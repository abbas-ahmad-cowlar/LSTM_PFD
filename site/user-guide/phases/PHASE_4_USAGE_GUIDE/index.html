<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Advanced Bearing Fault Diagnosis System - Production-Ready Research Platform"><meta name=author content="Syed Abbas Ahmad"><link href=https://abbas-ahmad-cowlar.github.io/LSTM_PFD/user-guide/phases/PHASE_4_USAGE_GUIDE/ rel=canonical><link rel=icon href=../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.1"><title>Phase 4: Transformer Architecture - Usage Guide - LSTM PFD Documentation</title><link rel=stylesheet href=../../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../stylesheets/extra.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#phase-4-transformer-architecture-usage-guide class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="LSTM PFD Documentation" class="md-header__button md-logo" aria-label="LSTM PFD Documentation" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m16 11.78 4.24-7.33 1.73 1-5.23 9.05-6.51-3.75L5.46 19H22v2H2V3h2v14.54L9.5 8z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> LSTM PFD Documentation </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Phase 4: Transformer Architecture - Usage Guide </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/abbas-ahmad-cowlar/LSTM_PFD title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> abbas-ahmad-cowlar/LSTM_PFD </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../../getting-started/ class=md-tabs__link> Getting Started </a> </li> <li class=md-tabs__item> <a href=../../ class=md-tabs__link> User Guide </a> </li> <li class=md-tabs__item> <a href=../../../api/ class=md-tabs__link> API Reference </a> </li> <li class=md-tabs__item> <a href=../../../research/ class=md-tabs__link> Research </a> </li> <li class=md-tabs__item> <a href=../../../DEPLOYMENT_GUIDE/ class=md-tabs__link> Deployment </a> </li> <li class=md-tabs__item> <a href=../../../../CHANGELOG.md class=md-tabs__link> Changelog </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="LSTM PFD Documentation" class="md-nav__button md-logo" aria-label="LSTM PFD Documentation" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m16 11.78 4.24-7.33 1.73 1-5.23 9.05-6.51-3.75L5.46 19H22v2H2V3h2v14.54L9.5 8z"/></svg> </a> LSTM PFD Documentation </label> <div class=md-nav__source> <a href=https://github.com/abbas-ahmad-cowlar/LSTM_PFD title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> abbas-ahmad-cowlar/LSTM_PFD </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Getting Started </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Getting Started </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../getting-started/ class=md-nav__link> <span class=md-ellipsis> Getting Started </span> </a> </li> <li class=md-nav__item> <a href=../../../getting-started/installation/ class=md-nav__link> <span class=md-ellipsis> Installation </span> </a> </li> <li class=md-nav__item> <a href=../../../getting-started/quickstart/ class=md-nav__link> <span class=md-ellipsis> Quick Start </span> </a> </li> <li class=md-nav__item> <a href=../../../getting-started/configuration/ class=md-nav__link> <span class=md-ellipsis> Configuration </span> </a> </li> <li class=md-nav__item> <a href=../../../getting-started/first-experiment/ class=md-nav__link> <span class=md-ellipsis> First Experiment </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> User Guide </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> User Guide </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../ class=md-nav__link> <span class=md-ellipsis> User Guide </span> </a> </li> <li class=md-nav__item> <a href=../../../USAGE_PHASE_11/ class=md-nav__link> <span class=md-ellipsis> Dashboard Usage </span> </a> </li> <li class=md-nav__item> <a href=../../../USER_GUIDE/ class=md-nav__link> <span class=md-ellipsis> User Guide </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> API Reference </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> API Reference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../api/ class=md-nav__link> <span class=md-ellipsis> API Reference </span> </a> </li> <li class=md-nav__item> <a href=../../../API_REFERENCE/ class=md-nav__link> <span class=md-ellipsis> REST API </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Research </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Research </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../research/ class=md-nav__link> <span class=md-ellipsis> Research </span> </a> </li> <li class=md-nav__item> <a href=../../../research/pinn-theory/ class=md-nav__link> <span class=md-ellipsis> PINN Theory </span> </a> </li> <li class=md-nav__item> <a href=../../../research/xai-methods/ class=md-nav__link> <span class=md-ellipsis> XAI Methods </span> </a> </li> <li class=md-nav__item> <a href=../../../research/ensemble-strategies/ class=md-nav__link> <span class=md-ellipsis> Ensemble Strategies </span> </a> </li> <li class=md-nav__item> <a href=../../../research/ablation-studies/ class=md-nav__link> <span class=md-ellipsis> Ablation Studies </span> </a> </li> <li class=md-nav__item> <a href=../../../research/reproducibility/ class=md-nav__link> <span class=md-ellipsis> Reproducibility </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Deployment </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Deployment </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../DEPLOYMENT_GUIDE/ class=md-nav__link> <span class=md-ellipsis> Deployment Guide </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../../CHANGELOG.md class=md-nav__link> <span class=md-ellipsis> Changelog </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#what-was-implemented class=md-nav__link> <span class=md-ellipsis> üìã What Was Implemented </span> </a> </li> <li class=md-nav__item> <a href=#quick-start class=md-nav__link> <span class=md-ellipsis> üöÄ Quick Start </span> </a> <nav class=md-nav aria-label="üöÄ Quick Start"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#step-1-install-dependencies class=md-nav__link> <span class=md-ellipsis> Step 1: Install Dependencies </span> </a> </li> <li class=md-nav__item> <a href=#step-2-basic-transformer-training class=md-nav__link> <span class=md-ellipsis> Step 2: Basic Transformer Training </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#advanced-usage class=md-nav__link> <span class=md-ellipsis> üéØ Advanced Usage </span> </a> <nav class=md-nav aria-label="üéØ Advanced Usage"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#option-1-vision-transformer-vit-style class=md-nav__link> <span class=md-ellipsis> Option 1: Vision Transformer (ViT) Style </span> </a> </li> <li class=md-nav__item> <a href=#option-2-cnn-transformer-hybrid-best-performance class=md-nav__link> <span class=md-ellipsis> Option 2: CNN-Transformer Hybrid (Best Performance) </span> </a> </li> <li class=md-nav__item> <a href=#option-3-efficient-attention-for-longer-signals class=md-nav__link> <span class=md-ellipsis> Option 3: Efficient Attention (for Longer Signals) </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#attention-visualization class=md-nav__link> <span class=md-ellipsis> üîç Attention Visualization </span> </a> <nav class=md-nav aria-label="üîç Attention Visualization"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#interactive-attention-dashboard class=md-nav__link> <span class=md-ellipsis> Interactive Attention Dashboard </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#model-comparison class=md-nav__link> <span class=md-ellipsis> üìä Model Comparison </span> </a> </li> <li class=md-nav__item> <a href=#hyperparameter-tuning class=md-nav__link> <span class=md-ellipsis> üéõÔ∏è Hyperparameter Tuning </span> </a> </li> <li class=md-nav__item> <a href=#troubleshooting class=md-nav__link> <span class=md-ellipsis> üêõ Troubleshooting </span> </a> <nav class=md-nav aria-label="üêõ Troubleshooting"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#issue-1-training-diverges-loss-nan class=md-nav__link> <span class=md-ellipsis> Issue 1: Training Diverges (Loss ‚Üí NaN) </span> </a> </li> <li class=md-nav__item> <a href=#issue-2-attention-weights-dont-sum-to-1 class=md-nav__link> <span class=md-ellipsis> Issue 2: Attention Weights Don't Sum to 1 </span> </a> </li> <li class=md-nav__item> <a href=#issue-3-out-of-memory class=md-nav__link> <span class=md-ellipsis> Issue 3: Out of Memory </span> </a> </li> <li class=md-nav__item> <a href=#issue-4-slower-than-cnn class=md-nav__link> <span class=md-ellipsis> Issue 4: Slower Than CNN </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#expected-results class=md-nav__link> <span class=md-ellipsis> üìà Expected Results </span> </a> </li> <li class=md-nav__item> <a href=#next-steps class=md-nav__link> <span class=md-ellipsis> üöÄ Next Steps </span> </a> </li> <li class=md-nav__item> <a href=#additional-resources class=md-nav__link> <span class=md-ellipsis> üìö Additional Resources </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=phase-4-transformer-architecture-usage-guide>Phase 4: Transformer Architecture - Usage Guide<a class=headerlink href=#phase-4-transformer-architecture-usage-guide title="Permanent link">&para;</a></h1> <p>This guide explains how to use the Transformer-based models for bearing fault diagnosis, leveraging self-attention mechanisms to capture long-range temporal dependencies in vibration signals.</p> <hr> <h2 id=what-was-implemented>üìã What Was Implemented<a class=headerlink href=#what-was-implemented title="Permanent link">&para;</a></h2> <p>Phase 4 implements <strong>Transformer encoder architecture</strong> adapted for time-series classification:</p> <ul> <li><strong>Core Transformer Components</strong>: Multi-head self-attention, positional encoding, transformer encoder layers</li> <li><strong>Patch-Based Processing</strong>: Convert 1D signals into sequences of patches for transformer input</li> <li><strong>Transformer Variants</strong>: Standard transformer, Vision Transformer (ViT) style, CNN-Transformer hybrid</li> <li><strong>Attention Visualization</strong>: Interactive tools to understand which time regions drive predictions</li> <li><strong>Specialized Training</strong>: Learning rate warmup, label smoothing, patch-based augmentation</li> </ul> <p><strong>Target Performance</strong>: 96-97% accuracy (matching or exceeding ResNet-34)</p> <hr> <h2 id=quick-start>üöÄ Quick Start<a class=headerlink href=#quick-start title="Permanent link">&para;</a></h2> <h3 id=step-1-install-dependencies>Step 1: Install Dependencies<a class=headerlink href=#step-1-install-dependencies title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=c1># Install required packages</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>pip<span class=w> </span>install<span class=w> </span>torch&gt;<span class=o>=</span><span class=m>2</span>.0.0<span class=w> </span>numpy<span class=w> </span>scipy<span class=w> </span>matplotlib<span class=w> </span>seaborn
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a>pip<span class=w> </span>install<span class=w> </span>einops<span class=w>  </span><span class=c1># For tensor operations (optional but recommended)</span>
</span></code></pre></div> <h3 id=step-2-basic-transformer-training>Step 2: Basic Transformer Training<a class=headerlink href=#step-2-basic-transformer-training title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=sd>train_transformer.py - Train Transformer model for fault diagnosis</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a><span class=kn>from</span><span class=w> </span><span class=nn>torch.utils.data</span><span class=w> </span><span class=kn>import</span> <span class=n>DataLoader</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a><span class=kn>from</span><span class=w> </span><span class=nn>models.transformer</span><span class=w> </span><span class=kn>import</span> <span class=n>create_transformer</span>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a><span class=kn>from</span><span class=w> </span><span class=nn>data.cnn_dataloader</span><span class=w> </span><span class=kn>import</span> <span class=n>SignalDataset</span>
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a><span class=kn>import</span><span class=w> </span><span class=nn>h5py</span>
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a>
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a><span class=c1># Load data</span>
</span><span id=__span-1-11><a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a><span class=k>with</span> <span class=n>h5py</span><span class=o>.</span><span class=n>File</span><span class=p>(</span><span class=s1>&#39;data/processed/signals_cache.h5&#39;</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span><span id=__span-1-12><a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a>    <span class=n>X_train</span> <span class=o>=</span> <span class=n>f</span><span class=p>[</span><span class=s1>&#39;train/signals&#39;</span><span class=p>][:]</span>
</span><span id=__span-1-13><a id=__codelineno-1-13 name=__codelineno-1-13 href=#__codelineno-1-13></a>    <span class=n>y_train</span> <span class=o>=</span> <span class=n>f</span><span class=p>[</span><span class=s1>&#39;train/labels&#39;</span><span class=p>][:]</span>
</span><span id=__span-1-14><a id=__codelineno-1-14 name=__codelineno-1-14 href=#__codelineno-1-14></a>    <span class=n>X_val</span> <span class=o>=</span> <span class=n>f</span><span class=p>[</span><span class=s1>&#39;val/signals&#39;</span><span class=p>][:]</span>
</span><span id=__span-1-15><a id=__codelineno-1-15 name=__codelineno-1-15 href=#__codelineno-1-15></a>    <span class=n>y_val</span> <span class=o>=</span> <span class=n>f</span><span class=p>[</span><span class=s1>&#39;val/labels&#39;</span><span class=p>][:]</span>
</span><span id=__span-1-16><a id=__codelineno-1-16 name=__codelineno-1-16 href=#__codelineno-1-16></a>
</span><span id=__span-1-17><a id=__codelineno-1-17 name=__codelineno-1-17 href=#__codelineno-1-17></a><span class=c1># Create datasets</span>
</span><span id=__span-1-18><a id=__codelineno-1-18 name=__codelineno-1-18 href=#__codelineno-1-18></a><span class=n>train_dataset</span> <span class=o>=</span> <span class=n>SignalDataset</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-1-19><a id=__codelineno-1-19 name=__codelineno-1-19 href=#__codelineno-1-19></a><span class=n>val_dataset</span> <span class=o>=</span> <span class=n>SignalDataset</span><span class=p>(</span><span class=n>X_val</span><span class=p>,</span> <span class=n>y_val</span><span class=p>)</span>
</span><span id=__span-1-20><a id=__codelineno-1-20 name=__codelineno-1-20 href=#__codelineno-1-20></a>
</span><span id=__span-1-21><a id=__codelineno-1-21 name=__codelineno-1-21 href=#__codelineno-1-21></a><span class=n>train_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>num_workers</span><span class=o>=</span><span class=mi>4</span><span class=p>)</span>
</span><span id=__span-1-22><a id=__codelineno-1-22 name=__codelineno-1-22 href=#__codelineno-1-22></a><span class=n>val_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>val_dataset</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>num_workers</span><span class=o>=</span><span class=mi>4</span><span class=p>)</span>
</span><span id=__span-1-23><a id=__codelineno-1-23 name=__codelineno-1-23 href=#__codelineno-1-23></a>
</span><span id=__span-1-24><a id=__codelineno-1-24 name=__codelineno-1-24 href=#__codelineno-1-24></a><span class=c1># Create Transformer model</span>
</span><span id=__span-1-25><a id=__codelineno-1-25 name=__codelineno-1-25 href=#__codelineno-1-25></a><span class=n>model</span> <span class=o>=</span> <span class=n>create_transformer</span><span class=p>(</span>
</span><span id=__span-1-26><a id=__codelineno-1-26 name=__codelineno-1-26 href=#__codelineno-1-26></a>    <span class=n>num_classes</span><span class=o>=</span><span class=mi>11</span><span class=p>,</span>           <span class=c1># 11 fault types</span>
</span><span id=__span-1-27><a id=__codelineno-1-27 name=__codelineno-1-27 href=#__codelineno-1-27></a>    <span class=n>input_channels</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>         <span class=c1># Mono signal</span>
</span><span id=__span-1-28><a id=__codelineno-1-28 name=__codelineno-1-28 href=#__codelineno-1-28></a>    <span class=n>patch_size</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>           <span class=c1># Patch size (102400/512 = 200 patches)</span>
</span><span id=__span-1-29><a id=__codelineno-1-29 name=__codelineno-1-29 href=#__codelineno-1-29></a>    <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span>              <span class=c1># Embedding dimension</span>
</span><span id=__span-1-30><a id=__codelineno-1-30 name=__codelineno-1-30 href=#__codelineno-1-30></a>    <span class=n>num_heads</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>              <span class=c1># Number of attention heads</span>
</span><span id=__span-1-31><a id=__codelineno-1-31 name=__codelineno-1-31 href=#__codelineno-1-31></a>    <span class=n>num_layers</span><span class=o>=</span><span class=mi>6</span><span class=p>,</span>             <span class=c1># Number of transformer blocks</span>
</span><span id=__span-1-32><a id=__codelineno-1-32 name=__codelineno-1-32 href=#__codelineno-1-32></a>    <span class=n>d_ff</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>                <span class=c1># FFN hidden dimension</span>
</span><span id=__span-1-33><a id=__codelineno-1-33 name=__codelineno-1-33 href=#__codelineno-1-33></a>    <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>              <span class=c1># Dropout rate</span>
</span><span id=__span-1-34><a id=__codelineno-1-34 name=__codelineno-1-34 href=#__codelineno-1-34></a>    <span class=n>learnable_pe</span><span class=o>=</span><span class=kc>True</span>         <span class=c1># Use learnable positional encoding</span>
</span><span id=__span-1-35><a id=__codelineno-1-35 name=__codelineno-1-35 href=#__codelineno-1-35></a><span class=p>)</span>
</span><span id=__span-1-36><a id=__codelineno-1-36 name=__codelineno-1-36 href=#__codelineno-1-36></a>
</span><span id=__span-1-37><a id=__codelineno-1-37 name=__codelineno-1-37 href=#__codelineno-1-37></a><span class=c1># Setup training</span>
</span><span id=__span-1-38><a id=__codelineno-1-38 name=__codelineno-1-38 href=#__codelineno-1-38></a><span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s1>&#39;cuda&#39;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span><span id=__span-1-39><a id=__codelineno-1-39 name=__codelineno-1-39 href=#__codelineno-1-39></a><span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-1-40><a id=__codelineno-1-40 name=__codelineno-1-40 href=#__codelineno-1-40></a>
</span><span id=__span-1-41><a id=__codelineno-1-41 name=__codelineno-1-41 href=#__codelineno-1-41></a><span class=n>criterion</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>(</span><span class=n>label_smoothing</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
</span><span id=__span-1-42><a id=__codelineno-1-42 name=__codelineno-1-42 href=#__codelineno-1-42></a><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>AdamW</span><span class=p>(</span>
</span><span id=__span-1-43><a id=__codelineno-1-43 name=__codelineno-1-43 href=#__codelineno-1-43></a>    <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span>
</span><span id=__span-1-44><a id=__codelineno-1-44 name=__codelineno-1-44 href=#__codelineno-1-44></a>    <span class=n>lr</span><span class=o>=</span><span class=mf>1e-4</span><span class=p>,</span>
</span><span id=__span-1-45><a id=__codelineno-1-45 name=__codelineno-1-45 href=#__codelineno-1-45></a>    <span class=n>weight_decay</span><span class=o>=</span><span class=mf>0.01</span>
</span><span id=__span-1-46><a id=__codelineno-1-46 name=__codelineno-1-46 href=#__codelineno-1-46></a><span class=p>)</span>
</span><span id=__span-1-47><a id=__codelineno-1-47 name=__codelineno-1-47 href=#__codelineno-1-47></a>
</span><span id=__span-1-48><a id=__codelineno-1-48 name=__codelineno-1-48 href=#__codelineno-1-48></a><span class=c1># Learning rate scheduler with warmup (critical for transformers!)</span>
</span><span id=__span-1-49><a id=__codelineno-1-49 name=__codelineno-1-49 href=#__codelineno-1-49></a><span class=kn>from</span><span class=w> </span><span class=nn>torch.optim.lr_scheduler</span><span class=w> </span><span class=kn>import</span> <span class=n>LambdaLR</span>
</span><span id=__span-1-50><a id=__codelineno-1-50 name=__codelineno-1-50 href=#__codelineno-1-50></a>
</span><span id=__span-1-51><a id=__codelineno-1-51 name=__codelineno-1-51 href=#__codelineno-1-51></a><span class=k>def</span><span class=w> </span><span class=nf>lr_lambda</span><span class=p>(</span><span class=n>epoch</span><span class=p>):</span>
</span><span id=__span-1-52><a id=__codelineno-1-52 name=__codelineno-1-52 href=#__codelineno-1-52></a>    <span class=n>warmup_epochs</span> <span class=o>=</span> <span class=mi>10</span>
</span><span id=__span-1-53><a id=__codelineno-1-53 name=__codelineno-1-53 href=#__codelineno-1-53></a>    <span class=k>if</span> <span class=n>epoch</span> <span class=o>&lt;</span> <span class=n>warmup_epochs</span><span class=p>:</span>
</span><span id=__span-1-54><a id=__codelineno-1-54 name=__codelineno-1-54 href=#__codelineno-1-54></a>        <span class=k>return</span> <span class=p>(</span><span class=n>epoch</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>warmup_epochs</span>
</span><span id=__span-1-55><a id=__codelineno-1-55 name=__codelineno-1-55 href=#__codelineno-1-55></a>    <span class=k>else</span><span class=p>:</span>
</span><span id=__span-1-56><a id=__codelineno-1-56 name=__codelineno-1-56 href=#__codelineno-1-56></a>        <span class=c1># Cosine annealing after warmup</span>
</span><span id=__span-1-57><a id=__codelineno-1-57 name=__codelineno-1-57 href=#__codelineno-1-57></a>        <span class=kn>import</span><span class=w> </span><span class=nn>math</span>
</span><span id=__span-1-58><a id=__codelineno-1-58 name=__codelineno-1-58 href=#__codelineno-1-58></a>        <span class=n>progress</span> <span class=o>=</span> <span class=p>(</span><span class=n>epoch</span> <span class=o>-</span> <span class=n>warmup_epochs</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=mi>100</span> <span class=o>-</span> <span class=n>warmup_epochs</span><span class=p>)</span>
</span><span id=__span-1-59><a id=__codelineno-1-59 name=__codelineno-1-59 href=#__codelineno-1-59></a>        <span class=k>return</span> <span class=mf>0.5</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>+</span> <span class=n>math</span><span class=o>.</span><span class=n>cos</span><span class=p>(</span><span class=n>math</span><span class=o>.</span><span class=n>pi</span> <span class=o>*</span> <span class=n>progress</span><span class=p>))</span>
</span><span id=__span-1-60><a id=__codelineno-1-60 name=__codelineno-1-60 href=#__codelineno-1-60></a>
</span><span id=__span-1-61><a id=__codelineno-1-61 name=__codelineno-1-61 href=#__codelineno-1-61></a><span class=n>scheduler</span> <span class=o>=</span> <span class=n>LambdaLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>lr_lambda</span><span class=p>)</span>
</span><span id=__span-1-62><a id=__codelineno-1-62 name=__codelineno-1-62 href=#__codelineno-1-62></a>
</span><span id=__span-1-63><a id=__codelineno-1-63 name=__codelineno-1-63 href=#__codelineno-1-63></a><span class=c1># Training loop</span>
</span><span id=__span-1-64><a id=__codelineno-1-64 name=__codelineno-1-64 href=#__codelineno-1-64></a><span class=n>num_epochs</span> <span class=o>=</span> <span class=mi>100</span>
</span><span id=__span-1-65><a id=__codelineno-1-65 name=__codelineno-1-65 href=#__codelineno-1-65></a><span class=n>best_val_acc</span> <span class=o>=</span> <span class=mf>0.0</span>
</span><span id=__span-1-66><a id=__codelineno-1-66 name=__codelineno-1-66 href=#__codelineno-1-66></a>
</span><span id=__span-1-67><a id=__codelineno-1-67 name=__codelineno-1-67 href=#__codelineno-1-67></a><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
</span><span id=__span-1-68><a id=__codelineno-1-68 name=__codelineno-1-68 href=#__codelineno-1-68></a>    <span class=c1># Training</span>
</span><span id=__span-1-69><a id=__codelineno-1-69 name=__codelineno-1-69 href=#__codelineno-1-69></a>    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span><span id=__span-1-70><a id=__codelineno-1-70 name=__codelineno-1-70 href=#__codelineno-1-70></a>    <span class=n>train_loss</span> <span class=o>=</span> <span class=mf>0.0</span>
</span><span id=__span-1-71><a id=__codelineno-1-71 name=__codelineno-1-71 href=#__codelineno-1-71></a>    <span class=n>train_correct</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-1-72><a id=__codelineno-1-72 name=__codelineno-1-72 href=#__codelineno-1-72></a>    <span class=n>train_total</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-1-73><a id=__codelineno-1-73 name=__codelineno-1-73 href=#__codelineno-1-73></a>
</span><span id=__span-1-74><a id=__codelineno-1-74 name=__codelineno-1-74 href=#__codelineno-1-74></a>    <span class=k>for</span> <span class=n>batch_idx</span><span class=p>,</span> <span class=p>(</span><span class=n>signals</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
</span><span id=__span-1-75><a id=__codelineno-1-75 name=__codelineno-1-75 href=#__codelineno-1-75></a>        <span class=n>signals</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>signals</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-1-76><a id=__codelineno-1-76 name=__codelineno-1-76 href=#__codelineno-1-76></a>
</span><span id=__span-1-77><a id=__codelineno-1-77 name=__codelineno-1-77 href=#__codelineno-1-77></a>        <span class=c1># Forward pass</span>
</span><span id=__span-1-78><a id=__codelineno-1-78 name=__codelineno-1-78 href=#__codelineno-1-78></a>        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>signals</span><span class=p>)</span>
</span><span id=__span-1-79><a id=__codelineno-1-79 name=__codelineno-1-79 href=#__codelineno-1-79></a>        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span><span id=__span-1-80><a id=__codelineno-1-80 name=__codelineno-1-80 href=#__codelineno-1-80></a>
</span><span id=__span-1-81><a id=__codelineno-1-81 name=__codelineno-1-81 href=#__codelineno-1-81></a>        <span class=c1># Backward pass</span>
</span><span id=__span-1-82><a id=__codelineno-1-82 name=__codelineno-1-82 href=#__codelineno-1-82></a>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span><span id=__span-1-83><a id=__codelineno-1-83 name=__codelineno-1-83 href=#__codelineno-1-83></a>        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-1-84><a id=__codelineno-1-84 name=__codelineno-1-84 href=#__codelineno-1-84></a>
</span><span id=__span-1-85><a id=__codelineno-1-85 name=__codelineno-1-85 href=#__codelineno-1-85></a>        <span class=c1># Gradient clipping (important for transformers)</span>
</span><span id=__span-1-86><a id=__codelineno-1-86 name=__codelineno-1-86 href=#__codelineno-1-86></a>        <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>clip_grad_norm_</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>max_norm</span><span class=o>=</span><span class=mf>1.0</span><span class=p>)</span>
</span><span id=__span-1-87><a id=__codelineno-1-87 name=__codelineno-1-87 href=#__codelineno-1-87></a>
</span><span id=__span-1-88><a id=__codelineno-1-88 name=__codelineno-1-88 href=#__codelineno-1-88></a>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span><span id=__span-1-89><a id=__codelineno-1-89 name=__codelineno-1-89 href=#__codelineno-1-89></a>
</span><span id=__span-1-90><a id=__codelineno-1-90 name=__codelineno-1-90 href=#__codelineno-1-90></a>        <span class=c1># Statistics</span>
</span><span id=__span-1-91><a id=__codelineno-1-91 name=__codelineno-1-91 href=#__codelineno-1-91></a>        <span class=n>train_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span><span id=__span-1-92><a id=__codelineno-1-92 name=__codelineno-1-92 href=#__codelineno-1-92></a>        <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-1-93><a id=__codelineno-1-93 name=__codelineno-1-93 href=#__codelineno-1-93></a>        <span class=n>train_total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span><span id=__span-1-94><a id=__codelineno-1-94 name=__codelineno-1-94 href=#__codelineno-1-94></a>        <span class=n>train_correct</span> <span class=o>+=</span> <span class=n>predicted</span><span class=o>.</span><span class=n>eq</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span><span id=__span-1-95><a id=__codelineno-1-95 name=__codelineno-1-95 href=#__codelineno-1-95></a>
</span><span id=__span-1-96><a id=__codelineno-1-96 name=__codelineno-1-96 href=#__codelineno-1-96></a>    <span class=c1># Validation</span>
</span><span id=__span-1-97><a id=__codelineno-1-97 name=__codelineno-1-97 href=#__codelineno-1-97></a>    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span><span id=__span-1-98><a id=__codelineno-1-98 name=__codelineno-1-98 href=#__codelineno-1-98></a>    <span class=n>val_loss</span> <span class=o>=</span> <span class=mf>0.0</span>
</span><span id=__span-1-99><a id=__codelineno-1-99 name=__codelineno-1-99 href=#__codelineno-1-99></a>    <span class=n>val_correct</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-1-100><a id=__codelineno-1-100 name=__codelineno-1-100 href=#__codelineno-1-100></a>    <span class=n>val_total</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-1-101><a id=__codelineno-1-101 name=__codelineno-1-101 href=#__codelineno-1-101></a>
</span><span id=__span-1-102><a id=__codelineno-1-102 name=__codelineno-1-102 href=#__codelineno-1-102></a>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span><span id=__span-1-103><a id=__codelineno-1-103 name=__codelineno-1-103 href=#__codelineno-1-103></a>        <span class=k>for</span> <span class=n>signals</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>val_loader</span><span class=p>:</span>
</span><span id=__span-1-104><a id=__codelineno-1-104 name=__codelineno-1-104 href=#__codelineno-1-104></a>            <span class=n>signals</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>signals</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-1-105><a id=__codelineno-1-105 name=__codelineno-1-105 href=#__codelineno-1-105></a>            <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>signals</span><span class=p>)</span>
</span><span id=__span-1-106><a id=__codelineno-1-106 name=__codelineno-1-106 href=#__codelineno-1-106></a>            <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span><span id=__span-1-107><a id=__codelineno-1-107 name=__codelineno-1-107 href=#__codelineno-1-107></a>
</span><span id=__span-1-108><a id=__codelineno-1-108 name=__codelineno-1-108 href=#__codelineno-1-108></a>            <span class=n>val_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span><span id=__span-1-109><a id=__codelineno-1-109 name=__codelineno-1-109 href=#__codelineno-1-109></a>            <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-1-110><a id=__codelineno-1-110 name=__codelineno-1-110 href=#__codelineno-1-110></a>            <span class=n>val_total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span><span id=__span-1-111><a id=__codelineno-1-111 name=__codelineno-1-111 href=#__codelineno-1-111></a>            <span class=n>val_correct</span> <span class=o>+=</span> <span class=n>predicted</span><span class=o>.</span><span class=n>eq</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span><span id=__span-1-112><a id=__codelineno-1-112 name=__codelineno-1-112 href=#__codelineno-1-112></a>
</span><span id=__span-1-113><a id=__codelineno-1-113 name=__codelineno-1-113 href=#__codelineno-1-113></a>    <span class=c1># Update learning rate</span>
</span><span id=__span-1-114><a id=__codelineno-1-114 name=__codelineno-1-114 href=#__codelineno-1-114></a>    <span class=n>scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span><span id=__span-1-115><a id=__codelineno-1-115 name=__codelineno-1-115 href=#__codelineno-1-115></a>
</span><span id=__span-1-116><a id=__codelineno-1-116 name=__codelineno-1-116 href=#__codelineno-1-116></a>    <span class=c1># Print epoch summary</span>
</span><span id=__span-1-117><a id=__codelineno-1-117 name=__codelineno-1-117 href=#__codelineno-1-117></a>    <span class=n>train_acc</span> <span class=o>=</span> <span class=mf>100.</span> <span class=o>*</span> <span class=n>train_correct</span> <span class=o>/</span> <span class=n>train_total</span>
</span><span id=__span-1-118><a id=__codelineno-1-118 name=__codelineno-1-118 href=#__codelineno-1-118></a>    <span class=n>val_acc</span> <span class=o>=</span> <span class=mf>100.</span> <span class=o>*</span> <span class=n>val_correct</span> <span class=o>/</span> <span class=n>val_total</span>
</span><span id=__span-1-119><a id=__codelineno-1-119 name=__codelineno-1-119 href=#__codelineno-1-119></a>
</span><span id=__span-1-120><a id=__codelineno-1-120 name=__codelineno-1-120 href=#__codelineno-1-120></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Epoch </span><span class=si>{</span><span class=n>epoch</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s1>/</span><span class=si>{</span><span class=n>num_epochs</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span><span id=__span-1-121><a id=__codelineno-1-121 name=__codelineno-1-121 href=#__codelineno-1-121></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;  Train Loss: </span><span class=si>{</span><span class=n>train_loss</span><span class=o>/</span><span class=nb>len</span><span class=p>(</span><span class=n>train_loader</span><span class=p>)</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1> | Train Acc: </span><span class=si>{</span><span class=n>train_acc</span><span class=si>:</span><span class=s1>.2f</span><span class=si>}</span><span class=s1>%&#39;</span><span class=p>)</span>
</span><span id=__span-1-122><a id=__codelineno-1-122 name=__codelineno-1-122 href=#__codelineno-1-122></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;  Val Loss: </span><span class=si>{</span><span class=n>val_loss</span><span class=o>/</span><span class=nb>len</span><span class=p>(</span><span class=n>val_loader</span><span class=p>)</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1> | Val Acc: </span><span class=si>{</span><span class=n>val_acc</span><span class=si>:</span><span class=s1>.2f</span><span class=si>}</span><span class=s1>%&#39;</span><span class=p>)</span>
</span><span id=__span-1-123><a id=__codelineno-1-123 name=__codelineno-1-123 href=#__codelineno-1-123></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;  LR: </span><span class=si>{</span><span class=n>scheduler</span><span class=o>.</span><span class=n>get_last_lr</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span><span class=si>:</span><span class=s1>.6f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span><span id=__span-1-124><a id=__codelineno-1-124 name=__codelineno-1-124 href=#__codelineno-1-124></a>
</span><span id=__span-1-125><a id=__codelineno-1-125 name=__codelineno-1-125 href=#__codelineno-1-125></a>    <span class=c1># Save best model</span>
</span><span id=__span-1-126><a id=__codelineno-1-126 name=__codelineno-1-126 href=#__codelineno-1-126></a>    <span class=k>if</span> <span class=n>val_acc</span> <span class=o>&gt;</span> <span class=n>best_val_acc</span><span class=p>:</span>
</span><span id=__span-1-127><a id=__codelineno-1-127 name=__codelineno-1-127 href=#__codelineno-1-127></a>        <span class=n>best_val_acc</span> <span class=o>=</span> <span class=n>val_acc</span>
</span><span id=__span-1-128><a id=__codelineno-1-128 name=__codelineno-1-128 href=#__codelineno-1-128></a>        <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>({</span>
</span><span id=__span-1-129><a id=__codelineno-1-129 name=__codelineno-1-129 href=#__codelineno-1-129></a>            <span class=s1>&#39;epoch&#39;</span><span class=p>:</span> <span class=n>epoch</span><span class=p>,</span>
</span><span id=__span-1-130><a id=__codelineno-1-130 name=__codelineno-1-130 href=#__codelineno-1-130></a>            <span class=s1>&#39;model_state_dict&#39;</span><span class=p>:</span> <span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
</span><span id=__span-1-131><a id=__codelineno-1-131 name=__codelineno-1-131 href=#__codelineno-1-131></a>            <span class=s1>&#39;optimizer_state_dict&#39;</span><span class=p>:</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
</span><span id=__span-1-132><a id=__codelineno-1-132 name=__codelineno-1-132 href=#__codelineno-1-132></a>            <span class=s1>&#39;val_acc&#39;</span><span class=p>:</span> <span class=n>val_acc</span><span class=p>,</span>
</span><span id=__span-1-133><a id=__codelineno-1-133 name=__codelineno-1-133 href=#__codelineno-1-133></a>        <span class=p>},</span> <span class=s1>&#39;checkpoints/phase4/best_transformer.pth&#39;</span><span class=p>)</span>
</span><span id=__span-1-134><a id=__codelineno-1-134 name=__codelineno-1-134 href=#__codelineno-1-134></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;  ‚Üí Saved best model (Val Acc: </span><span class=si>{</span><span class=n>val_acc</span><span class=si>:</span><span class=s1>.2f</span><span class=si>}</span><span class=s1>%)&#39;</span><span class=p>)</span>
</span><span id=__span-1-135><a id=__codelineno-1-135 name=__codelineno-1-135 href=#__codelineno-1-135></a>
</span><span id=__span-1-136><a id=__codelineno-1-136 name=__codelineno-1-136 href=#__codelineno-1-136></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>Training complete! Best validation accuracy: </span><span class=si>{</span><span class=n>best_val_acc</span><span class=si>:</span><span class=s1>.2f</span><span class=si>}</span><span class=s1>%&#39;</span><span class=p>)</span>
</span></code></pre></div> <hr> <h2 id=advanced-usage>üéØ Advanced Usage<a class=headerlink href=#advanced-usage title="Permanent link">&para;</a></h2> <h3 id=option-1-vision-transformer-vit-style>Option 1: Vision Transformer (ViT) Style<a class=headerlink href=#option-1-vision-transformer-vit-style title="Permanent link">&para;</a></h3> <p>Use a learnable classification token instead of global average pooling:</p> <blockquote> <p><strong>Note</strong>: VisionTransformer1D is not yet fully implemented. The standard SignalTransformer uses global average pooling for classification. To implement ViT-style classification with a [CLS] token, you would need to modify the SignalTransformer class to add a learnable token at the beginning of the patch sequence.</p> </blockquote> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># Example concept (not yet implemented):</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=c1># from models.transformer import SignalTransformer</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=c1>#</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a><span class=c1># # You would need to modify SignalTransformer to support use_cls_token parameter</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a><span class=c1># model = SignalTransformer(</span>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a><span class=c1>#     num_classes=11,</span>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a><span class=c1>#     patch_size=512,</span>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a><span class=c1>#     d_model=256,</span>
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a><span class=c1>#     num_heads=8,</span>
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a><span class=c1>#     num_layers=6,</span>
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a><span class=c1>#     d_ff=1024,</span>
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a><span class=c1>#     dropout=0.1,</span>
</span><span id=__span-2-13><a id=__codelineno-2-13 name=__codelineno-2-13 href=#__codelineno-2-13></a><span class=c1>#     # use_cls_token=True  # Not yet supported - requires modification</span>
</span><span id=__span-2-14><a id=__codelineno-2-14 name=__codelineno-2-14 href=#__codelineno-2-14></a><span class=c1># )</span>
</span></code></pre></div> <h3 id=option-2-cnn-transformer-hybrid-best-performance>Option 2: CNN-Transformer Hybrid (Best Performance)<a class=headerlink href=#option-2-cnn-transformer-hybrid-best-performance title="Permanent link">&para;</a></h3> <p>Combine CNN feature extraction with Transformer reasoning:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=kn>from</span><span class=w> </span><span class=nn>models.resnet</span><span class=w> </span><span class=kn>import</span> <span class=n>create_resnet18_1d</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=kn>from</span><span class=w> </span><span class=nn>transformers</span><span class=w> </span><span class=kn>import</span> <span class=n>create_signal_transformer</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a><span class=k>class</span><span class=w> </span><span class=nc>CNNTransformerHybrid</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>num_classes</span><span class=o>=</span><span class=mi>11</span><span class=p>):</span>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a>
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a>        <span class=c1># CNN backbone (feature extractor)</span>
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a>        <span class=n>resnet</span> <span class=o>=</span> <span class=n>create_resnet18_1d</span><span class=p>(</span><span class=n>num_classes</span><span class=o>=</span><span class=mi>11</span><span class=p>)</span>
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a>        <span class=c1># Remove final FC layer</span>
</span><span id=__span-3-12><a id=__codelineno-3-12 name=__codelineno-3-12 href=#__codelineno-3-12></a>        <span class=bp>self</span><span class=o>.</span><span class=n>cnn_backbone</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=o>*</span><span class=nb>list</span><span class=p>(</span><span class=n>resnet</span><span class=o>.</span><span class=n>children</span><span class=p>())[:</span><span class=o>-</span><span class=mi>1</span><span class=p>])</span>
</span><span id=__span-3-13><a id=__codelineno-3-13 name=__codelineno-3-13 href=#__codelineno-3-13></a>
</span><span id=__span-3-14><a id=__codelineno-3-14 name=__codelineno-3-14 href=#__codelineno-3-14></a>        <span class=c1># Transformer encoder</span>
</span><span id=__span-3-15><a id=__codelineno-3-15 name=__codelineno-3-15 href=#__codelineno-3-15></a>        <span class=bp>self</span><span class=o>.</span><span class=n>transformer</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>TransformerEncoder</span><span class=p>(</span>
</span><span id=__span-3-16><a id=__codelineno-3-16 name=__codelineno-3-16 href=#__codelineno-3-16></a>            <span class=n>nn</span><span class=o>.</span><span class=n>TransformerEncoderLayer</span><span class=p>(</span>
</span><span id=__span-3-17><a id=__codelineno-3-17 name=__codelineno-3-17 href=#__codelineno-3-17></a>                <span class=n>d_model</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>  <span class=c1># ResNet-18 output channels</span>
</span><span id=__span-3-18><a id=__codelineno-3-18 name=__codelineno-3-18 href=#__codelineno-3-18></a>                <span class=n>nhead</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
</span><span id=__span-3-19><a id=__codelineno-3-19 name=__codelineno-3-19 href=#__codelineno-3-19></a>                <span class=n>dim_feedforward</span><span class=o>=</span><span class=mi>2048</span><span class=p>,</span>
</span><span id=__span-3-20><a id=__codelineno-3-20 name=__codelineno-3-20 href=#__codelineno-3-20></a>                <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>
</span><span id=__span-3-21><a id=__codelineno-3-21 name=__codelineno-3-21 href=#__codelineno-3-21></a>                <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-3-22><a id=__codelineno-3-22 name=__codelineno-3-22 href=#__codelineno-3-22></a>            <span class=p>),</span>
</span><span id=__span-3-23><a id=__codelineno-3-23 name=__codelineno-3-23 href=#__codelineno-3-23></a>            <span class=n>num_layers</span><span class=o>=</span><span class=mi>4</span>
</span><span id=__span-3-24><a id=__codelineno-3-24 name=__codelineno-3-24 href=#__codelineno-3-24></a>        <span class=p>)</span>
</span><span id=__span-3-25><a id=__codelineno-3-25 name=__codelineno-3-25 href=#__codelineno-3-25></a>
</span><span id=__span-3-26><a id=__codelineno-3-26 name=__codelineno-3-26 href=#__codelineno-3-26></a>        <span class=c1># Classification head</span>
</span><span id=__span-3-27><a id=__codelineno-3-27 name=__codelineno-3-27 href=#__codelineno-3-27></a>        <span class=bp>self</span><span class=o>.</span><span class=n>fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>)</span>
</span><span id=__span-3-28><a id=__codelineno-3-28 name=__codelineno-3-28 href=#__codelineno-3-28></a>
</span><span id=__span-3-29><a id=__codelineno-3-29 name=__codelineno-3-29 href=#__codelineno-3-29></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span><span id=__span-3-30><a id=__codelineno-3-30 name=__codelineno-3-30 href=#__codelineno-3-30></a>        <span class=c1># CNN feature extraction</span>
</span><span id=__span-3-31><a id=__codelineno-3-31 name=__codelineno-3-31 href=#__codelineno-3-31></a>        <span class=n>features</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>cnn_backbone</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># [B, 512, seq_len]</span>
</span><span id=__span-3-32><a id=__codelineno-3-32 name=__codelineno-3-32 href=#__codelineno-3-32></a>
</span><span id=__span-3-33><a id=__codelineno-3-33 name=__codelineno-3-33 href=#__codelineno-3-33></a>        <span class=c1># Permute for transformer: [B, 512, seq_len] -&gt; [B, seq_len, 512]</span>
</span><span id=__span-3-34><a id=__codelineno-3-34 name=__codelineno-3-34 href=#__codelineno-3-34></a>        <span class=n>features</span> <span class=o>=</span> <span class=n>features</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span><span id=__span-3-35><a id=__codelineno-3-35 name=__codelineno-3-35 href=#__codelineno-3-35></a>
</span><span id=__span-3-36><a id=__codelineno-3-36 name=__codelineno-3-36 href=#__codelineno-3-36></a>        <span class=c1># Transformer reasoning</span>
</span><span id=__span-3-37><a id=__codelineno-3-37 name=__codelineno-3-37 href=#__codelineno-3-37></a>        <span class=n>features</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>transformer</span><span class=p>(</span><span class=n>features</span><span class=p>)</span>
</span><span id=__span-3-38><a id=__codelineno-3-38 name=__codelineno-3-38 href=#__codelineno-3-38></a>
</span><span id=__span-3-39><a id=__codelineno-3-39 name=__codelineno-3-39 href=#__codelineno-3-39></a>        <span class=c1># Global average pooling</span>
</span><span id=__span-3-40><a id=__codelineno-3-40 name=__codelineno-3-40 href=#__codelineno-3-40></a>        <span class=n>features</span> <span class=o>=</span> <span class=n>features</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># [B, 512]</span>
</span><span id=__span-3-41><a id=__codelineno-3-41 name=__codelineno-3-41 href=#__codelineno-3-41></a>
</span><span id=__span-3-42><a id=__codelineno-3-42 name=__codelineno-3-42 href=#__codelineno-3-42></a>        <span class=c1># Classification</span>
</span><span id=__span-3-43><a id=__codelineno-3-43 name=__codelineno-3-43 href=#__codelineno-3-43></a>        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc</span><span class=p>(</span><span class=n>features</span><span class=p>)</span>
</span><span id=__span-3-44><a id=__codelineno-3-44 name=__codelineno-3-44 href=#__codelineno-3-44></a>        <span class=k>return</span> <span class=n>output</span>
</span><span id=__span-3-45><a id=__codelineno-3-45 name=__codelineno-3-45 href=#__codelineno-3-45></a>
</span><span id=__span-3-46><a id=__codelineno-3-46 name=__codelineno-3-46 href=#__codelineno-3-46></a><span class=c1># Create and train hybrid model</span>
</span><span id=__span-3-47><a id=__codelineno-3-47 name=__codelineno-3-47 href=#__codelineno-3-47></a><span class=n>model</span> <span class=o>=</span> <span class=n>CNNTransformerHybrid</span><span class=p>(</span><span class=n>num_classes</span><span class=o>=</span><span class=mi>11</span><span class=p>)</span>
</span><span id=__span-3-48><a id=__codelineno-3-48 name=__codelineno-3-48 href=#__codelineno-3-48></a><span class=c1># Train as usual - expected accuracy: 97-98%</span>
</span></code></pre></div> <h3 id=option-3-efficient-attention-for-longer-signals>Option 3: Efficient Attention (for Longer Signals)<a class=headerlink href=#option-3-efficient-attention-for-longer-signals title="Permanent link">&para;</a></h3> <p>For signals longer than 102,400 samples, use larger patch sizes to reduce memory:</p> <blockquote> <p><strong>Note</strong>: Efficient attention mechanisms (Performer, Linformer, etc.) are not yet implemented. For longer signals, use larger patch sizes to reduce the number of patches and memory requirements.</p> </blockquote> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=kn>from</span><span class=w> </span><span class=nn>models.transformer</span><span class=w> </span><span class=kn>import</span> <span class=n>create_transformer</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=c1># For longer signals, increase patch_size to keep sequence length manageable</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a><span class=n>model</span> <span class=o>=</span> <span class=n>create_transformer</span><span class=p>(</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a>    <span class=n>num_classes</span><span class=o>=</span><span class=mi>11</span><span class=p>,</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>    <span class=n>patch_size</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>      <span class=c1># Larger patches: 204800/1024 = 200 patches (same as before)</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a>    <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>    <span class=n>num_heads</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a>    <span class=n>num_layers</span><span class=o>=</span><span class=mi>6</span><span class=p>,</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a>    <span class=n>d_ff</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a>    <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a><span class=p>)</span>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a>
</span><span id=__span-4-14><a id=__codelineno-4-14 name=__codelineno-4-14 href=#__codelineno-4-14></a><span class=c1># Alternative: Use fewer patches with larger patch size</span>
</span><span id=__span-4-15><a id=__codelineno-4-15 name=__codelineno-4-15 href=#__codelineno-4-15></a><span class=c1># patch_size=2048 ‚Üí 102 patches (lower memory, faster)</span>
</span></code></pre></div> <hr> <h2 id=attention-visualization>üîç Attention Visualization<a class=headerlink href=#attention-visualization title="Permanent link">&para;</a></h2> <p>Understand what the model is focusing on:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=sd>visualize_attention.py - Visualize attention patterns</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a><span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a><span class=kn>from</span><span class=w> </span><span class=nn>models.transformer</span><span class=w> </span><span class=kn>import</span> <span class=n>create_transformer</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a><span class=c1># Load trained model</span>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a><span class=n>checkpoint</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>&#39;checkpoints/phase4/best_transformer.pth&#39;</span><span class=p>)</span>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a><span class=n>model</span> <span class=o>=</span> <span class=n>create_transformer</span><span class=p>(</span><span class=n>num_classes</span><span class=o>=</span><span class=mi>11</span><span class=p>,</span> <span class=n>patch_size</span><span class=o>=</span><span class=mi>512</span><span class=p>)</span>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a><span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>checkpoint</span><span class=p>[</span><span class=s1>&#39;model_state_dict&#39;</span><span class=p>])</span>
</span><span id=__span-5-13><a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a><span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span><span id=__span-5-14><a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a>
</span><span id=__span-5-15><a id=__codelineno-5-15 name=__codelineno-5-15 href=#__codelineno-5-15></a><span class=c1># Load a test signal</span>
</span><span id=__span-5-16><a id=__codelineno-5-16 name=__codelineno-5-16 href=#__codelineno-5-16></a><span class=n>signal</span> <span class=o>=</span> <span class=n>X_test</span><span class=p>[</span><span class=mi>0</span><span class=p>:</span><span class=mi>1</span><span class=p>]</span>  <span class=c1># Shape: [1, 1, 102400]</span>
</span><span id=__span-5-17><a id=__codelineno-5-17 name=__codelineno-5-17 href=#__codelineno-5-17></a><span class=n>true_label</span> <span class=o>=</span> <span class=n>y_test</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span><span id=__span-5-18><a id=__codelineno-5-18 name=__codelineno-5-18 href=#__codelineno-5-18></a>
</span><span id=__span-5-19><a id=__codelineno-5-19 name=__codelineno-5-19 href=#__codelineno-5-19></a><span class=c1># Get prediction and attention weights</span>
</span><span id=__span-5-20><a id=__codelineno-5-20 name=__codelineno-5-20 href=#__codelineno-5-20></a><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span><span id=__span-5-21><a id=__codelineno-5-21 name=__codelineno-5-21 href=#__codelineno-5-21></a>    <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>signal</span><span class=p>)</span>
</span><span id=__span-5-22><a id=__codelineno-5-22 name=__codelineno-5-22 href=#__codelineno-5-22></a>    <span class=n>predicted_class</span> <span class=o>=</span> <span class=n>output</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span><span id=__span-5-23><a id=__codelineno-5-23 name=__codelineno-5-23 href=#__codelineno-5-23></a>
</span><span id=__span-5-24><a id=__codelineno-5-24 name=__codelineno-5-24 href=#__codelineno-5-24></a>    <span class=c1># Extract attention weights from last layer</span>
</span><span id=__span-5-25><a id=__codelineno-5-25 name=__codelineno-5-25 href=#__codelineno-5-25></a>    <span class=c1># This requires model to have get_attention_weights() method</span>
</span><span id=__span-5-26><a id=__codelineno-5-26 name=__codelineno-5-26 href=#__codelineno-5-26></a>    <span class=n>attention_weights</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>get_attention_weights</span><span class=p>(</span><span class=n>signal</span><span class=p>,</span> <span class=n>layer_idx</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-5-27><a id=__codelineno-5-27 name=__codelineno-5-27 href=#__codelineno-5-27></a>    <span class=c1># Shape: [1, n_heads, n_patches, n_patches]</span>
</span><span id=__span-5-28><a id=__codelineno-5-28 name=__codelineno-5-28 href=#__codelineno-5-28></a>
</span><span id=__span-5-29><a id=__codelineno-5-29 name=__codelineno-5-29 href=#__codelineno-5-29></a><span class=c1># Visualize attention</span>
</span><span id=__span-5-30><a id=__codelineno-5-30 name=__codelineno-5-30 href=#__codelineno-5-30></a><span class=n>n_heads</span> <span class=o>=</span> <span class=n>attention_weights</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span><span id=__span-5-31><a id=__codelineno-5-31 name=__codelineno-5-31 href=#__codelineno-5-31></a><span class=n>n_patches</span> <span class=o>=</span> <span class=n>attention_weights</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span>
</span><span id=__span-5-32><a id=__codelineno-5-32 name=__codelineno-5-32 href=#__codelineno-5-32></a><span class=n>patch_size</span> <span class=o>=</span> <span class=mi>512</span>
</span><span id=__span-5-33><a id=__codelineno-5-33 name=__codelineno-5-33 href=#__codelineno-5-33></a>
</span><span id=__span-5-34><a id=__codelineno-5-34 name=__codelineno-5-34 href=#__codelineno-5-34></a><span class=c1># Average attention across all heads</span>
</span><span id=__span-5-35><a id=__codelineno-5-35 name=__codelineno-5-35 href=#__codelineno-5-35></a><span class=n>avg_attention</span> <span class=o>=</span> <span class=n>attention_weights</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>  <span class=c1># [n_patches, n_patches]</span>
</span><span id=__span-5-36><a id=__codelineno-5-36 name=__codelineno-5-36 href=#__codelineno-5-36></a>
</span><span id=__span-5-37><a id=__codelineno-5-37 name=__codelineno-5-37 href=#__codelineno-5-37></a><span class=c1># For each query patch, show which key patches it attends to</span>
</span><span id=__span-5-38><a id=__codelineno-5-38 name=__codelineno-5-38 href=#__codelineno-5-38></a><span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>15</span><span class=p>,</span> <span class=mi>8</span><span class=p>))</span>
</span><span id=__span-5-39><a id=__codelineno-5-39 name=__codelineno-5-39 href=#__codelineno-5-39></a>
</span><span id=__span-5-40><a id=__codelineno-5-40 name=__codelineno-5-40 href=#__codelineno-5-40></a><span class=c1># Plot 1: Signal with attention overlay</span>
</span><span id=__span-5-41><a id=__codelineno-5-41 name=__codelineno-5-41 href=#__codelineno-5-41></a><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>signal</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>(),</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Signal&#39;</span><span class=p>)</span>
</span><span id=__span-5-42><a id=__codelineno-5-42 name=__codelineno-5-42 href=#__codelineno-5-42></a><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Signal (True: </span><span class=si>{</span><span class=n>true_label</span><span class=si>}</span><span class=s1>, Predicted: </span><span class=si>{</span><span class=n>predicted_class</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
</span><span id=__span-5-43><a id=__codelineno-5-43 name=__codelineno-5-43 href=#__codelineno-5-43></a><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Sample&#39;</span><span class=p>)</span>
</span><span id=__span-5-44><a id=__codelineno-5-44 name=__codelineno-5-44 href=#__codelineno-5-44></a><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Amplitude&#39;</span><span class=p>)</span>
</span><span id=__span-5-45><a id=__codelineno-5-45 name=__codelineno-5-45 href=#__codelineno-5-45></a>
</span><span id=__span-5-46><a id=__codelineno-5-46 name=__codelineno-5-46 href=#__codelineno-5-46></a><span class=c1># Overlay attention importance (aggregate attention received by each patch)</span>
</span><span id=__span-5-47><a id=__codelineno-5-47 name=__codelineno-5-47 href=#__codelineno-5-47></a><span class=n>attention_importance</span> <span class=o>=</span> <span class=n>avg_attention</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># Average attention received</span>
</span><span id=__span-5-48><a id=__codelineno-5-48 name=__codelineno-5-48 href=#__codelineno-5-48></a><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_patches</span><span class=p>):</span>
</span><span id=__span-5-49><a id=__codelineno-5-49 name=__codelineno-5-49 href=#__codelineno-5-49></a>    <span class=n>start_idx</span> <span class=o>=</span> <span class=n>i</span> <span class=o>*</span> <span class=n>patch_size</span>
</span><span id=__span-5-50><a id=__codelineno-5-50 name=__codelineno-5-50 href=#__codelineno-5-50></a>    <span class=n>end_idx</span> <span class=o>=</span> <span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>patch_size</span>
</span><span id=__span-5-51><a id=__codelineno-5-51 name=__codelineno-5-51 href=#__codelineno-5-51></a>    <span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>axvspan</span><span class=p>(</span><span class=n>start_idx</span><span class=p>,</span> <span class=n>end_idx</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=n>attention_importance</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>)</span>
</span><span id=__span-5-52><a id=__codelineno-5-52 name=__codelineno-5-52 href=#__codelineno-5-52></a>
</span><span id=__span-5-53><a id=__codelineno-5-53 name=__codelineno-5-53 href=#__codelineno-5-53></a><span class=c1># Plot 2: Attention heatmap</span>
</span><span id=__span-5-54><a id=__codelineno-5-54 name=__codelineno-5-54 href=#__codelineno-5-54></a><span class=n>im</span> <span class=o>=</span> <span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>avg_attention</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;viridis&#39;</span><span class=p>,</span> <span class=n>aspect</span><span class=o>=</span><span class=s1>&#39;auto&#39;</span><span class=p>)</span>
</span><span id=__span-5-55><a id=__codelineno-5-55 name=__codelineno-5-55 href=#__codelineno-5-55></a><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Attention Heatmap (Query patches √ó Key patches)&#39;</span><span class=p>)</span>
</span><span id=__span-5-56><a id=__codelineno-5-56 name=__codelineno-5-56 href=#__codelineno-5-56></a><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Key Patch Index&#39;</span><span class=p>)</span>
</span><span id=__span-5-57><a id=__codelineno-5-57 name=__codelineno-5-57 href=#__codelineno-5-57></a><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Query Patch Index&#39;</span><span class=p>)</span>
</span><span id=__span-5-58><a id=__codelineno-5-58 name=__codelineno-5-58 href=#__codelineno-5-58></a><span class=n>plt</span><span class=o>.</span><span class=n>colorbar</span><span class=p>(</span><span class=n>im</span><span class=p>,</span> <span class=n>ax</span><span class=o>=</span><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Attention Weight&#39;</span><span class=p>)</span>
</span><span id=__span-5-59><a id=__codelineno-5-59 name=__codelineno-5-59 href=#__codelineno-5-59></a>
</span><span id=__span-5-60><a id=__codelineno-5-60 name=__codelineno-5-60 href=#__codelineno-5-60></a><span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span><span id=__span-5-61><a id=__codelineno-5-61 name=__codelineno-5-61 href=#__codelineno-5-61></a><span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=s1>&#39;results/phase4/attention_visualization.png&#39;</span><span class=p>,</span> <span class=n>dpi</span><span class=o>=</span><span class=mi>300</span><span class=p>)</span>
</span><span id=__span-5-62><a id=__codelineno-5-62 name=__codelineno-5-62 href=#__codelineno-5-62></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span><span id=__span-5-63><a id=__codelineno-5-63 name=__codelineno-5-63 href=#__codelineno-5-63></a>
</span><span id=__span-5-64><a id=__codelineno-5-64 name=__codelineno-5-64 href=#__codelineno-5-64></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Most attended patches: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>argsort</span><span class=p>(</span><span class=n>attention_importance</span><span class=p>)[</span><span class=o>-</span><span class=mi>10</span><span class=p>:][::</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=interactive-attention-dashboard>Interactive Attention Dashboard<a class=headerlink href=#interactive-attention-dashboard title="Permanent link">&para;</a></h3> <p>Launch an interactive dashboard to explore attention patterns:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=sd>attention_dashboard.py - Interactive Streamlit dashboard</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=kn>import</span><span class=w> </span><span class=nn>streamlit</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>st</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a><span class=kn>from</span><span class=w> </span><span class=nn>models.transformer</span><span class=w> </span><span class=kn>import</span> <span class=n>create_transformer</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a><span class=c1># Note: Run with: streamlit run attention_dashboard.py</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a><span class=n>st</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&quot;Transformer Attention Visualization&quot;</span><span class=p>)</span>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a><span class=c1># Load model</span>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a><span class=n>checkpoint</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>&#39;checkpoints/phase4/best_transformer.pth&#39;</span><span class=p>)</span>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a><span class=n>model</span> <span class=o>=</span> <span class=n>create_transformer</span><span class=p>(</span><span class=n>num_classes</span><span class=o>=</span><span class=mi>11</span><span class=p>,</span> <span class=n>patch_size</span><span class=o>=</span><span class=mi>512</span><span class=p>)</span>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a><span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>checkpoint</span><span class=p>[</span><span class=s1>&#39;model_state_dict&#39;</span><span class=p>])</span>
</span><span id=__span-6-17><a id=__codelineno-6-17 name=__codelineno-6-17 href=#__codelineno-6-17></a><span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span><span id=__span-6-18><a id=__codelineno-6-18 name=__codelineno-6-18 href=#__codelineno-6-18></a>
</span><span id=__span-6-19><a id=__codelineno-6-19 name=__codelineno-6-19 href=#__codelineno-6-19></a><span class=c1># Upload signal</span>
</span><span id=__span-6-20><a id=__codelineno-6-20 name=__codelineno-6-20 href=#__codelineno-6-20></a><span class=n>uploaded_file</span> <span class=o>=</span> <span class=n>st</span><span class=o>.</span><span class=n>file_uploader</span><span class=p>(</span><span class=s2>&quot;Upload signal (.npy file)&quot;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;npy&#39;</span><span class=p>])</span>
</span><span id=__span-6-21><a id=__codelineno-6-21 name=__codelineno-6-21 href=#__codelineno-6-21></a><span class=k>if</span> <span class=n>uploaded_file</span><span class=p>:</span>
</span><span id=__span-6-22><a id=__codelineno-6-22 name=__codelineno-6-22 href=#__codelineno-6-22></a>    <span class=n>signal</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>uploaded_file</span><span class=p>)</span>
</span><span id=__span-6-23><a id=__codelineno-6-23 name=__codelineno-6-23 href=#__codelineno-6-23></a>
</span><span id=__span-6-24><a id=__codelineno-6-24 name=__codelineno-6-24 href=#__codelineno-6-24></a>    <span class=c1># Predict</span>
</span><span id=__span-6-25><a id=__codelineno-6-25 name=__codelineno-6-25 href=#__codelineno-6-25></a>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span><span id=__span-6-26><a id=__codelineno-6-26 name=__codelineno-6-26 href=#__codelineno-6-26></a>        <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>signal</span><span class=p>)</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>))</span>
</span><span id=__span-6-27><a id=__codelineno-6-27 name=__codelineno-6-27 href=#__codelineno-6-27></a>        <span class=n>predicted_class</span> <span class=o>=</span> <span class=n>output</span><span class=o>.</span><span class=n>argmax</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span><span id=__span-6-28><a id=__codelineno-6-28 name=__codelineno-6-28 href=#__codelineno-6-28></a>        <span class=n>probabilities</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span><span id=__span-6-29><a id=__codelineno-6-29 name=__codelineno-6-29 href=#__codelineno-6-29></a>
</span><span id=__span-6-30><a id=__codelineno-6-30 name=__codelineno-6-30 href=#__codelineno-6-30></a>    <span class=c1># Display prediction</span>
</span><span id=__span-6-31><a id=__codelineno-6-31 name=__codelineno-6-31 href=#__codelineno-6-31></a>    <span class=n>st</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;**Predicted Fault Type**: </span><span class=si>{</span><span class=n>predicted_class</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-6-32><a id=__codelineno-6-32 name=__codelineno-6-32 href=#__codelineno-6-32></a>    <span class=n>st</span><span class=o>.</span><span class=n>bar_chart</span><span class=p>(</span><span class=n>probabilities</span><span class=o>.</span><span class=n>numpy</span><span class=p>())</span>
</span><span id=__span-6-33><a id=__codelineno-6-33 name=__codelineno-6-33 href=#__codelineno-6-33></a>
</span><span id=__span-6-34><a id=__codelineno-6-34 name=__codelineno-6-34 href=#__codelineno-6-34></a>    <span class=c1># Select layer to visualize</span>
</span><span id=__span-6-35><a id=__codelineno-6-35 name=__codelineno-6-35 href=#__codelineno-6-35></a>    <span class=n>layer_idx</span> <span class=o>=</span> <span class=n>st</span><span class=o>.</span><span class=n>slider</span><span class=p>(</span><span class=s2>&quot;Select Transformer Layer&quot;</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>5</span><span class=p>)</span>
</span><span id=__span-6-36><a id=__codelineno-6-36 name=__codelineno-6-36 href=#__codelineno-6-36></a>
</span><span id=__span-6-37><a id=__codelineno-6-37 name=__codelineno-6-37 href=#__codelineno-6-37></a>    <span class=c1># Get attention weights</span>
</span><span id=__span-6-38><a id=__codelineno-6-38 name=__codelineno-6-38 href=#__codelineno-6-38></a>    <span class=n>attention</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>get_attention_weights</span><span class=p>(</span>
</span><span id=__span-6-39><a id=__codelineno-6-39 name=__codelineno-6-39 href=#__codelineno-6-39></a>        <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>signal</span><span class=p>)</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span>
</span><span id=__span-6-40><a id=__codelineno-6-40 name=__codelineno-6-40 href=#__codelineno-6-40></a>        <span class=n>layer_idx</span><span class=o>=</span><span class=n>layer_idx</span>
</span><span id=__span-6-41><a id=__codelineno-6-41 name=__codelineno-6-41 href=#__codelineno-6-41></a>    <span class=p>)</span>
</span><span id=__span-6-42><a id=__codelineno-6-42 name=__codelineno-6-42 href=#__codelineno-6-42></a>
</span><span id=__span-6-43><a id=__codelineno-6-43 name=__codelineno-6-43 href=#__codelineno-6-43></a>    <span class=c1># Visualize</span>
</span><span id=__span-6-44><a id=__codelineno-6-44 name=__codelineno-6-44 href=#__codelineno-6-44></a>    <span class=n>fig</span> <span class=o>=</span> <span class=n>plot_attention_heatmap</span><span class=p>(</span><span class=n>attention</span><span class=p>,</span> <span class=n>signal</span><span class=p>)</span>
</span><span id=__span-6-45><a id=__codelineno-6-45 name=__codelineno-6-45 href=#__codelineno-6-45></a>    <span class=n>st</span><span class=o>.</span><span class=n>pyplot</span><span class=p>(</span><span class=n>fig</span><span class=p>)</span>
</span></code></pre></div> <hr> <h2 id=model-comparison>üìä Model Comparison<a class=headerlink href=#model-comparison title="Permanent link">&para;</a></h2> <p>Compare Transformer with CNN models:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a><span class=sd>compare_models.py - Compare Transformer vs ResNet vs Hybrid</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=kn>from</span><span class=w> </span><span class=nn>models.transformer</span><span class=w> </span><span class=kn>import</span> <span class=n>create_transformer</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a><span class=kn>from</span><span class=w> </span><span class=nn>models.resnet_1d</span><span class=w> </span><span class=kn>import</span> <span class=n>create_resnet34_1d</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a><span class=kn>from</span><span class=w> </span><span class=nn>models.model_factory</span><span class=w> </span><span class=kn>import</span> <span class=n>load_pretrained</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a><span class=kn>from</span><span class=w> </span><span class=nn>evaluation.evaluator</span><span class=w> </span><span class=kn>import</span> <span class=n>evaluate_model</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a><span class=c1># Load models</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a><span class=c1># Transformer</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a><span class=n>transformer_checkpoint</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>&#39;checkpoints/phase4/transformer.pth&#39;</span><span class=p>)</span>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a><span class=n>transformer</span> <span class=o>=</span> <span class=n>create_transformer</span><span class=p>(</span><span class=n>num_classes</span><span class=o>=</span><span class=mi>11</span><span class=p>,</span> <span class=n>patch_size</span><span class=o>=</span><span class=mi>512</span><span class=p>)</span>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a><span class=n>transformer</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>transformer_checkpoint</span><span class=p>[</span><span class=s1>&#39;model_state_dict&#39;</span><span class=p>])</span>
</span><span id=__span-7-15><a id=__codelineno-7-15 name=__codelineno-7-15 href=#__codelineno-7-15></a>
</span><span id=__span-7-16><a id=__codelineno-7-16 name=__codelineno-7-16 href=#__codelineno-7-16></a><span class=c1># ResNet-34</span>
</span><span id=__span-7-17><a id=__codelineno-7-17 name=__codelineno-7-17 href=#__codelineno-7-17></a><span class=n>resnet34</span> <span class=o>=</span> <span class=n>load_pretrained</span><span class=p>(</span><span class=s1>&#39;resnet34&#39;</span><span class=p>,</span> <span class=s1>&#39;checkpoints/phase3/resnet34.pth&#39;</span><span class=p>,</span> <span class=n>num_classes</span><span class=o>=</span><span class=mi>11</span><span class=p>)</span>
</span><span id=__span-7-18><a id=__codelineno-7-18 name=__codelineno-7-18 href=#__codelineno-7-18></a>
</span><span id=__span-7-19><a id=__codelineno-7-19 name=__codelineno-7-19 href=#__codelineno-7-19></a><span class=c1># CNN-Transformer Hybrid (if available)</span>
</span><span id=__span-7-20><a id=__codelineno-7-20 name=__codelineno-7-20 href=#__codelineno-7-20></a><span class=c1># hybrid = torch.load(&#39;checkpoints/phase4/cnn_transformer_hybrid.pth&#39;)</span>
</span><span id=__span-7-21><a id=__codelineno-7-21 name=__codelineno-7-21 href=#__codelineno-7-21></a>
</span><span id=__span-7-22><a id=__codelineno-7-22 name=__codelineno-7-22 href=#__codelineno-7-22></a><span class=c1># Evaluate on test set</span>
</span><span id=__span-7-23><a id=__codelineno-7-23 name=__codelineno-7-23 href=#__codelineno-7-23></a><span class=n>models</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-7-24><a id=__codelineno-7-24 name=__codelineno-7-24 href=#__codelineno-7-24></a>    <span class=s1>&#39;Transformer&#39;</span><span class=p>:</span> <span class=n>transformer</span><span class=p>,</span>
</span><span id=__span-7-25><a id=__codelineno-7-25 name=__codelineno-7-25 href=#__codelineno-7-25></a>    <span class=s1>&#39;ResNet-34&#39;</span><span class=p>:</span> <span class=n>resnet34</span><span class=p>,</span>
</span><span id=__span-7-26><a id=__codelineno-7-26 name=__codelineno-7-26 href=#__codelineno-7-26></a>    <span class=s1>&#39;CNN-Transformer Hybrid&#39;</span><span class=p>:</span> <span class=n>hybrid</span>
</span><span id=__span-7-27><a id=__codelineno-7-27 name=__codelineno-7-27 href=#__codelineno-7-27></a><span class=p>}</span>
</span><span id=__span-7-28><a id=__codelineno-7-28 name=__codelineno-7-28 href=#__codelineno-7-28></a>
</span><span id=__span-7-29><a id=__codelineno-7-29 name=__codelineno-7-29 href=#__codelineno-7-29></a><span class=n>results</span> <span class=o>=</span> <span class=p>{}</span>
</span><span id=__span-7-30><a id=__codelineno-7-30 name=__codelineno-7-30 href=#__codelineno-7-30></a><span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>model</span> <span class=ow>in</span> <span class=n>models</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span><span id=__span-7-31><a id=__codelineno-7-31 name=__codelineno-7-31 href=#__codelineno-7-31></a>    <span class=n>metrics</span> <span class=o>=</span> <span class=n>evaluate_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>test_loader</span><span class=p>)</span>
</span><span id=__span-7-32><a id=__codelineno-7-32 name=__codelineno-7-32 href=#__codelineno-7-32></a>    <span class=n>results</span><span class=p>[</span><span class=n>name</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-7-33><a id=__codelineno-7-33 name=__codelineno-7-33 href=#__codelineno-7-33></a>        <span class=s1>&#39;Accuracy&#39;</span><span class=p>:</span> <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;accuracy&#39;</span><span class=p>],</span>
</span><span id=__span-7-34><a id=__codelineno-7-34 name=__codelineno-7-34 href=#__codelineno-7-34></a>        <span class=s1>&#39;F1 Score&#39;</span><span class=p>:</span> <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;f1_weighted&#39;</span><span class=p>],</span>
</span><span id=__span-7-35><a id=__codelineno-7-35 name=__codelineno-7-35 href=#__codelineno-7-35></a>        <span class=s1>&#39;Inference Time (ms)&#39;</span><span class=p>:</span> <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;avg_inference_time_ms&#39;</span><span class=p>],</span>
</span><span id=__span-7-36><a id=__codelineno-7-36 name=__codelineno-7-36 href=#__codelineno-7-36></a>        <span class=s1>&#39;Parameters (M)&#39;</span><span class=p>:</span> <span class=nb>sum</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span> <span class=o>/</span> <span class=mf>1e6</span>
</span><span id=__span-7-37><a id=__codelineno-7-37 name=__codelineno-7-37 href=#__codelineno-7-37></a>    <span class=p>}</span>
</span><span id=__span-7-38><a id=__codelineno-7-38 name=__codelineno-7-38 href=#__codelineno-7-38></a>
</span><span id=__span-7-39><a id=__codelineno-7-39 name=__codelineno-7-39 href=#__codelineno-7-39></a><span class=c1># Display comparison</span>
</span><span id=__span-7-40><a id=__codelineno-7-40 name=__codelineno-7-40 href=#__codelineno-7-40></a><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
</span><span id=__span-7-41><a id=__codelineno-7-41 name=__codelineno-7-41 href=#__codelineno-7-41></a><span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>results</span><span class=p>)</span><span class=o>.</span><span class=n>T</span>
</span><span id=__span-7-42><a id=__codelineno-7-42 name=__codelineno-7-42 href=#__codelineno-7-42></a><span class=nb>print</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
</span><span id=__span-7-43><a id=__codelineno-7-43 name=__codelineno-7-43 href=#__codelineno-7-43></a>
</span><span id=__span-7-44><a id=__codelineno-7-44 name=__codelineno-7-44 href=#__codelineno-7-44></a><span class=c1># Expected results:</span>
</span><span id=__span-7-45><a id=__codelineno-7-45 name=__codelineno-7-45 href=#__codelineno-7-45></a><span class=c1># ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</span>
</span><span id=__span-7-46><a id=__codelineno-7-46 name=__codelineno-7-46 href=#__codelineno-7-46></a><span class=c1># ‚îÇ Model                    ‚îÇ Accuracy ‚îÇ F1 Score ‚îÇ Inference Time (ms) ‚îÇ Parameters (M) ‚îÇ</span>
</span><span id=__span-7-47><a id=__codelineno-7-47 name=__codelineno-7-47 href=#__codelineno-7-47></a><span class=c1># ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§</span>
</span><span id=__span-7-48><a id=__codelineno-7-48 name=__codelineno-7-48 href=#__codelineno-7-48></a><span class=c1># ‚îÇ Transformer              ‚îÇ  96.5%   ‚îÇ  0.964   ‚îÇ       42.3         ‚îÇ      5.2       ‚îÇ</span>
</span><span id=__span-7-49><a id=__codelineno-7-49 name=__codelineno-7-49 href=#__codelineno-7-49></a><span class=c1># ‚îÇ ResNet-34                ‚îÇ  96.8%   ‚îÇ  0.967   ‚îÇ       28.5         ‚îÇ      8.1       ‚îÇ</span>
</span><span id=__span-7-50><a id=__codelineno-7-50 name=__codelineno-7-50 href=#__codelineno-7-50></a><span class=c1># ‚îÇ CNN-Transformer Hybrid   ‚îÇ  97.4%   ‚îÇ  0.973   ‚îÇ       51.7         ‚îÇ     11.3       ‚îÇ</span>
</span><span id=__span-7-51><a id=__codelineno-7-51 name=__codelineno-7-51 href=#__codelineno-7-51></a><span class=c1># ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</span>
</span></code></pre></div> <hr> <h2 id=hyperparameter-tuning>üéõÔ∏è Hyperparameter Tuning<a class=headerlink href=#hyperparameter-tuning title="Permanent link">&para;</a></h2> <p>Key hyperparameters for Transformer models:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=kn>from</span><span class=w> </span><span class=nn>optuna</span><span class=w> </span><span class=kn>import</span> <span class=n>create_study</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a><span class=k>def</span><span class=w> </span><span class=nf>objective</span><span class=p>(</span><span class=n>trial</span><span class=p>):</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a>    <span class=c1># Hyperparameters to tune</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a>    <span class=n>d_model</span> <span class=o>=</span> <span class=n>trial</span><span class=o>.</span><span class=n>suggest_categorical</span><span class=p>(</span><span class=s1>&#39;d_model&#39;</span><span class=p>,</span> <span class=p>[</span><span class=mi>128</span><span class=p>,</span> <span class=mi>256</span><span class=p>,</span> <span class=mi>512</span><span class=p>])</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a>    <span class=n>nhead</span> <span class=o>=</span> <span class=n>trial</span><span class=o>.</span><span class=n>suggest_categorical</span><span class=p>(</span><span class=s1>&#39;nhead&#39;</span><span class=p>,</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>16</span><span class=p>])</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a>    <span class=n>num_layers</span> <span class=o>=</span> <span class=n>trial</span><span class=o>.</span><span class=n>suggest_int</span><span class=p>(</span><span class=s1>&#39;num_layers&#39;</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>8</span><span class=p>)</span>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a>    <span class=n>dropout</span> <span class=o>=</span> <span class=n>trial</span><span class=o>.</span><span class=n>suggest_float</span><span class=p>(</span><span class=s1>&#39;dropout&#39;</span><span class=p>,</span> <span class=mf>0.0</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>)</span>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a>    <span class=n>lr</span> <span class=o>=</span> <span class=n>trial</span><span class=o>.</span><span class=n>suggest_loguniform</span><span class=p>(</span><span class=s1>&#39;lr&#39;</span><span class=p>,</span> <span class=mf>1e-5</span><span class=p>,</span> <span class=mf>1e-3</span><span class=p>)</span>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a>    <span class=n>warmup_epochs</span> <span class=o>=</span> <span class=n>trial</span><span class=o>.</span><span class=n>suggest_int</span><span class=p>(</span><span class=s1>&#39;warmup_epochs&#39;</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>)</span>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a>    <span class=c1># Create model</span>
</span><span id=__span-8-13><a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a>    <span class=kn>from</span><span class=w> </span><span class=nn>models.transformer</span><span class=w> </span><span class=kn>import</span> <span class=n>create_transformer</span>
</span><span id=__span-8-14><a id=__codelineno-8-14 name=__codelineno-8-14 href=#__codelineno-8-14></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>create_transformer</span><span class=p>(</span>
</span><span id=__span-8-15><a id=__codelineno-8-15 name=__codelineno-8-15 href=#__codelineno-8-15></a>        <span class=n>num_classes</span><span class=o>=</span><span class=mi>11</span><span class=p>,</span>
</span><span id=__span-8-16><a id=__codelineno-8-16 name=__codelineno-8-16 href=#__codelineno-8-16></a>        <span class=n>patch_size</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>
</span><span id=__span-8-17><a id=__codelineno-8-17 name=__codelineno-8-17 href=#__codelineno-8-17></a>        <span class=n>d_model</span><span class=o>=</span><span class=n>d_model</span><span class=p>,</span>
</span><span id=__span-8-18><a id=__codelineno-8-18 name=__codelineno-8-18 href=#__codelineno-8-18></a>        <span class=n>num_heads</span><span class=o>=</span><span class=n>nhead</span><span class=p>,</span>
</span><span id=__span-8-19><a id=__codelineno-8-19 name=__codelineno-8-19 href=#__codelineno-8-19></a>        <span class=n>num_layers</span><span class=o>=</span><span class=n>num_layers</span><span class=p>,</span>
</span><span id=__span-8-20><a id=__codelineno-8-20 name=__codelineno-8-20 href=#__codelineno-8-20></a>        <span class=n>d_ff</span><span class=o>=</span><span class=n>d_model</span> <span class=o>*</span> <span class=mi>4</span><span class=p>,</span>  <span class=c1># Standard ratio</span>
</span><span id=__span-8-21><a id=__codelineno-8-21 name=__codelineno-8-21 href=#__codelineno-8-21></a>        <span class=n>dropout</span><span class=o>=</span><span class=n>dropout</span>
</span><span id=__span-8-22><a id=__codelineno-8-22 name=__codelineno-8-22 href=#__codelineno-8-22></a>    <span class=p>)</span>
</span><span id=__span-8-23><a id=__codelineno-8-23 name=__codelineno-8-23 href=#__codelineno-8-23></a>
</span><span id=__span-8-24><a id=__codelineno-8-24 name=__codelineno-8-24 href=#__codelineno-8-24></a>    <span class=c1># Train and return validation accuracy</span>
</span><span id=__span-8-25><a id=__codelineno-8-25 name=__codelineno-8-25 href=#__codelineno-8-25></a>    <span class=n>val_acc</span> <span class=o>=</span> <span class=n>train_and_evaluate</span><span class=p>(</span>
</span><span id=__span-8-26><a id=__codelineno-8-26 name=__codelineno-8-26 href=#__codelineno-8-26></a>        <span class=n>model</span><span class=p>,</span> <span class=n>train_loader</span><span class=p>,</span> <span class=n>val_loader</span><span class=p>,</span>
</span><span id=__span-8-27><a id=__codelineno-8-27 name=__codelineno-8-27 href=#__codelineno-8-27></a>        <span class=n>lr</span><span class=o>=</span><span class=n>lr</span><span class=p>,</span> <span class=n>warmup_epochs</span><span class=o>=</span><span class=n>warmup_epochs</span>
</span><span id=__span-8-28><a id=__codelineno-8-28 name=__codelineno-8-28 href=#__codelineno-8-28></a>    <span class=p>)</span>
</span><span id=__span-8-29><a id=__codelineno-8-29 name=__codelineno-8-29 href=#__codelineno-8-29></a>
</span><span id=__span-8-30><a id=__codelineno-8-30 name=__codelineno-8-30 href=#__codelineno-8-30></a>    <span class=k>return</span> <span class=n>val_acc</span>
</span><span id=__span-8-31><a id=__codelineno-8-31 name=__codelineno-8-31 href=#__codelineno-8-31></a>
</span><span id=__span-8-32><a id=__codelineno-8-32 name=__codelineno-8-32 href=#__codelineno-8-32></a><span class=c1># Run optimization</span>
</span><span id=__span-8-33><a id=__codelineno-8-33 name=__codelineno-8-33 href=#__codelineno-8-33></a><span class=n>study</span> <span class=o>=</span> <span class=n>create_study</span><span class=p>(</span><span class=n>direction</span><span class=o>=</span><span class=s1>&#39;maximize&#39;</span><span class=p>)</span>
</span><span id=__span-8-34><a id=__codelineno-8-34 name=__codelineno-8-34 href=#__codelineno-8-34></a><span class=n>study</span><span class=o>.</span><span class=n>optimize</span><span class=p>(</span><span class=n>objective</span><span class=p>,</span> <span class=n>n_trials</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span><span id=__span-8-35><a id=__codelineno-8-35 name=__codelineno-8-35 href=#__codelineno-8-35></a>
</span><span id=__span-8-36><a id=__codelineno-8-36 name=__codelineno-8-36 href=#__codelineno-8-36></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Best hyperparameters: </span><span class=si>{</span><span class=n>study</span><span class=o>.</span><span class=n>best_params</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-8-37><a id=__codelineno-8-37 name=__codelineno-8-37 href=#__codelineno-8-37></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Best validation accuracy: </span><span class=si>{</span><span class=n>study</span><span class=o>.</span><span class=n>best_value</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Recommended Starting Values:</strong> - <code>d_model</code>: 256 (good balance between capacity and speed) - <code>num_heads</code>: 8 (standard choice) - <code>num_layers</code>: 6 (proven effective for time series) - <code>d_ff</code>: 1024 (4x d_model) - <code>dropout</code>: 0.1 (prevent overfitting) - <code>lr</code>: 1e-4 with 10-epoch warmup (critical!) - <code>patch_size</code>: 512 (results in 200 patches, default value)</p> <hr> <h2 id=troubleshooting>üêõ Troubleshooting<a class=headerlink href=#troubleshooting title="Permanent link">&para;</a></h2> <h3 id=issue-1-training-diverges-loss-nan>Issue 1: Training Diverges (Loss ‚Üí NaN)<a class=headerlink href=#issue-1-training-diverges-loss-nan title="Permanent link">&para;</a></h3> <p><strong>Solution</strong>: Ensure learning rate warmup is enabled</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=c1># BAD: No warmup</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>1e-3</span><span class=p>)</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=c1># GOOD: With warmup</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a><span class=k>def</span><span class=w> </span><span class=nf>lr_lambda</span><span class=p>(</span><span class=n>epoch</span><span class=p>):</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a>    <span class=k>if</span> <span class=n>epoch</span> <span class=o>&lt;</span> <span class=mi>10</span><span class=p>:</span>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a>        <span class=k>return</span> <span class=p>(</span><span class=n>epoch</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=mi>10</span>  <span class=c1># Linear warmup</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a>    <span class=k>return</span> <span class=mf>1.0</span>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a><span class=n>scheduler</span> <span class=o>=</span> <span class=n>LambdaLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>lr_lambda</span><span class=p>)</span>
</span></code></pre></div> <h3 id=issue-2-attention-weights-dont-sum-to-1>Issue 2: Attention Weights Don't Sum to 1<a class=headerlink href=#issue-2-attention-weights-dont-sum-to-1 title="Permanent link">&para;</a></h3> <p><strong>Check</strong>: Softmax is applied correctly in multi-head attention</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=c1># In multi_head_attention.py, verify:</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=n>scores</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>Q</span><span class=p>,</span> <span class=n>K</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>))</span> <span class=o>/</span> <span class=n>math</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>d_k</span><span class=p>)</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a><span class=n>attn_weights</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>scores</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># Sum over key dimension</span>
</span></code></pre></div> <h3 id=issue-3-out-of-memory>Issue 3: Out of Memory<a class=headerlink href=#issue-3-out-of-memory title="Permanent link">&para;</a></h3> <p><strong>Solutions</strong>: - Reduce batch size: <code>batch_size=16</code> instead of <code>32</code> - Reduce number of patches: Use <code>patch_size=1024</code> (100 patches instead of 200) - Use gradient checkpointing (trades compute for memory) - Use efficient attention (Performer) for linear memory complexity</p> <h3 id=issue-4-slower-than-cnn>Issue 4: Slower Than CNN<a class=headerlink href=#issue-4-slower-than-cnn title="Permanent link">&para;</a></h3> <p><strong>Expected</strong>: Transformers are slower due to attention computation - Transformer: ~40-50ms inference time - ResNet-34: ~25-30ms inference time - <strong>Solution</strong>: Use CNN-Transformer hybrid or optimize with TorchScript/ONNX</p> <hr> <h2 id=expected-results>üìà Expected Results<a class=headerlink href=#expected-results title="Permanent link">&para;</a></h2> <table> <thead> <tr> <th>Metric</th> <th>Target</th> <th>Typical Result</th> </tr> </thead> <tbody> <tr> <td>Test Accuracy</td> <td>96-97%</td> <td>96.5% (standard), 97.4% (hybrid)</td> </tr> <tr> <td>Training Time</td> <td>6-10 hours (GPU)</td> <td>~8 hours (V100)</td> </tr> <tr> <td>Inference Time</td> <td>&lt;50ms</td> <td>~42ms (single signal)</td> </tr> <tr> <td>Model Size</td> <td>5-15M params</td> <td>~5.2M (standard), ~11.3M (hybrid)</td> </tr> <tr> <td>Per-Class Recall</td> <td>‚â•85% for 10/11 classes</td> <td>87-98% per class</td> </tr> </tbody> </table> <p><strong>When to Use Transformer:</strong> - ‚úÖ When interpretability is important (attention visualization) - ‚úÖ When long-range dependencies matter (combined faults) - ‚úÖ When you have sufficient data (&gt;1000 samples)</p> <p><strong>When to Use CNN Instead:</strong> - ‚úÖ When inference speed is critical (&lt;30ms) - ‚úÖ When working with limited data (&lt;500 samples) - ‚úÖ When local patterns dominate (most single faults)</p> <hr> <h2 id=next-steps>üöÄ Next Steps<a class=headerlink href=#next-steps title="Permanent link">&para;</a></h2> <p>After Phase 4, you can:</p> <ol> <li><strong>Phase 5</strong>: Apply Transformer to spectrograms (2D patches)</li> <li><strong>Phase 6</strong>: Integrate physics constraints with attention mechanisms</li> <li><strong>Phase 7</strong>: Use attention weights as built-in explainability</li> <li><strong>Phase 8</strong>: Ensemble Transformer with CNNs for best performance</li> </ol> <hr> <h2 id=additional-resources>üìö Additional Resources<a class=headerlink href=#additional-resources title="Permanent link">&para;</a></h2> <ul> <li><strong>Paper</strong>: <a href=https://arxiv.org/abs/1706.03762>"Attention Is All You Need"</a> - Original Transformer paper</li> <li><strong>Paper</strong>: <a href=https://arxiv.org/abs/2010.11929>"An Image is Worth 16x16 Words"</a> - Vision Transformer (ViT)</li> <li><strong>Tutorial</strong>: <code>notebooks/phase4_transformer_tutorial.ipynb</code> - Interactive walkthrough</li> <li><strong>Plan Document</strong>: <code>Phase_4.md</code> - Complete architecture details</li> </ul> <hr> <p><strong>Phase 4 Complete!</strong> You now have transformer-based models that achieve 96-97% accuracy with built-in interpretability through attention visualization. üéâ</p> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024-2026 Syed Abbas Ahmad </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/abbas-ahmad-cowlar/LSTM_PFD target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"annotate": null, "base": "../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.path", "navigation.top", "navigation.footer", "search.suggest", "search.highlight", "content.tabs.link", "content.code.copy", "content.code.annotate"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script> <script src=../../../assets/javascripts/bundle.79ae519e.min.js></script> <script src=../../../javascripts/mathjax.js></script> <script src=https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>