<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Advanced Bearing Fault Diagnosis System - Production-Ready Research Platform"><meta name=author content="Syed Abbas Ahmad"><link href=https://abbas-ahmad-cowlar.github.io/LSTM_PFD/archive/planning/Phase_2/ rel=canonical><link rel=icon href=../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.1"><title>Phase 2 - LSTM PFD Documentation</title><link rel=stylesheet href=../../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../stylesheets/extra.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#phase-2-1d-convolutional-neural-network-implementation class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="LSTM PFD Documentation" class="md-header__button md-logo" aria-label="LSTM PFD Documentation" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m16 11.78 4.24-7.33 1.73 1-5.23 9.05-6.51-3.75L5.46 19H22v2H2V3h2v14.54L9.5 8z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> LSTM PFD Documentation </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Phase 2 </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/abbas-ahmad-cowlar/LSTM_PFD title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> abbas-ahmad-cowlar/LSTM_PFD </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../../getting-started/ class=md-tabs__link> Getting Started </a> </li> <li class=md-tabs__item> <a href=../../../user-guide/ class=md-tabs__link> User Guide </a> </li> <li class=md-tabs__item> <a href=../../../api/ class=md-tabs__link> API Reference </a> </li> <li class=md-tabs__item> <a href=../../../research/ class=md-tabs__link> Research </a> </li> <li class=md-tabs__item> <a href=../../../DEPLOYMENT_GUIDE/ class=md-tabs__link> Deployment </a> </li> <li class=md-tabs__item> <a href=../../../../CHANGELOG.md class=md-tabs__link> Changelog </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="LSTM PFD Documentation" class="md-nav__button md-logo" aria-label="LSTM PFD Documentation" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m16 11.78 4.24-7.33 1.73 1-5.23 9.05-6.51-3.75L5.46 19H22v2H2V3h2v14.54L9.5 8z"/></svg> </a> LSTM PFD Documentation </label> <div class=md-nav__source> <a href=https://github.com/abbas-ahmad-cowlar/LSTM_PFD title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> abbas-ahmad-cowlar/LSTM_PFD </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Getting Started </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Getting Started </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../getting-started/ class=md-nav__link> <span class=md-ellipsis> Getting Started </span> </a> </li> <li class=md-nav__item> <a href=../../../getting-started/installation/ class=md-nav__link> <span class=md-ellipsis> Installation </span> </a> </li> <li class=md-nav__item> <a href=../../../getting-started/quickstart/ class=md-nav__link> <span class=md-ellipsis> Quick Start </span> </a> </li> <li class=md-nav__item> <a href=../../../getting-started/configuration/ class=md-nav__link> <span class=md-ellipsis> Configuration </span> </a> </li> <li class=md-nav__item> <a href=../../../getting-started/first-experiment/ class=md-nav__link> <span class=md-ellipsis> First Experiment </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> User Guide </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> User Guide </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../user-guide/ class=md-nav__link> <span class=md-ellipsis> User Guide </span> </a> </li> <li class=md-nav__item> <a href=../../../USAGE_PHASE_11/ class=md-nav__link> <span class=md-ellipsis> Dashboard Usage </span> </a> </li> <li class=md-nav__item> <a href=../../../USER_GUIDE/ class=md-nav__link> <span class=md-ellipsis> User Guide </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> API Reference </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> API Reference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../api/ class=md-nav__link> <span class=md-ellipsis> API Reference </span> </a> </li> <li class=md-nav__item> <a href=../../../API_REFERENCE/ class=md-nav__link> <span class=md-ellipsis> REST API </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Research </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Research </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../research/ class=md-nav__link> <span class=md-ellipsis> Research </span> </a> </li> <li class=md-nav__item> <a href=../../../research/pinn-theory/ class=md-nav__link> <span class=md-ellipsis> PINN Theory </span> </a> </li> <li class=md-nav__item> <a href=../../../research/xai-methods/ class=md-nav__link> <span class=md-ellipsis> XAI Methods </span> </a> </li> <li class=md-nav__item> <a href=../../../research/ensemble-strategies/ class=md-nav__link> <span class=md-ellipsis> Ensemble Strategies </span> </a> </li> <li class=md-nav__item> <a href=../../../research/ablation-studies/ class=md-nav__link> <span class=md-ellipsis> Ablation Studies </span> </a> </li> <li class=md-nav__item> <a href=../../../research/reproducibility/ class=md-nav__link> <span class=md-ellipsis> Reproducibility </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Deployment </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Deployment </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../DEPLOYMENT_GUIDE/ class=md-nav__link> <span class=md-ellipsis> Deployment Guide </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../../CHANGELOG.md class=md-nav__link> <span class=md-ellipsis> Changelog </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#phase-2-1d-convolutional-neural-network-implementation class=md-nav__link> <span class=md-ellipsis> PHASE 2: 1D Convolutional Neural Network Implementation </span> </a> <nav class=md-nav aria-label="PHASE 2: 1D Convolutional Neural Network Implementation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#phase-objective class=md-nav__link> <span class=md-ellipsis> Phase Objective </span> </a> </li> <li class=md-nav__item> <a href=#complete-file-list-24-files class=md-nav__link> <span class=md-ellipsis> Complete File List (24 files) </span> </a> </li> <li class=md-nav__item> <a href=#architecture-decisions class=md-nav__link> <span class=md-ellipsis> Architecture Decisions </span> </a> </li> <li class=md-nav__item> <a href=#data-flow class=md-nav__link> <span class=md-ellipsis> Data Flow </span> </a> </li> <li class=md-nav__item> <a href=#integration-points class=md-nav__link> <span class=md-ellipsis> Integration Points </span> </a> </li> <li class=md-nav__item> <a href=#testing-strategy class=md-nav__link> <span class=md-ellipsis> Testing Strategy </span> </a> </li> <li class=md-nav__item> <a href=#acceptance-criteria class=md-nav__link> <span class=md-ellipsis> Acceptance Criteria </span> </a> </li> <li class=md-nav__item> <a href=#estimated-effort class=md-nav__link> <span class=md-ellipsis> Estimated Effort </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1>Phase 2</h1> <h2 id=phase-2-1d-convolutional-neural-network-implementation><strong>PHASE 2: 1D Convolutional Neural Network Implementation</strong><a class=headerlink href=#phase-2-1d-convolutional-neural-network-implementation title="Permanent link">&para;</a></h2> <h3 id=phase-objective>Phase Objective<a class=headerlink href=#phase-objective title="Permanent link">&para;</a></h3> <p>Implement and train a 1D CNN architecture for end-to-end learning from raw vibration signals, bypassing manual feature engineering. Achieve performance comparable to classical ML baseline (target: 93-96% test accuracy) while establishing the foundation for more advanced deep learning models in subsequent phases.</p> <h3 id=complete-file-list-24-files>Complete File List (24 files)<a class=headerlink href=#complete-file-list-24-files title="Permanent link">&para;</a></h3> <h4 id=1-cnn-architecture-5-files><strong>1. CNN Architecture (5 files)</strong><a class=headerlink href=#1-cnn-architecture-5-files title="Permanent link">&para;</a></h4> <p><strong><code>models/cnn/cnn_1d.py</code></strong> <em>(Enhanced from Phase 0)</em> - <strong>Purpose</strong>: Main 1D CNN architecture with configurable depth - <strong>Key Classes</strong>: - <code>CNN1D(BaseModel)</code>: Core CNN architecture - <code>ConvBlock</code>: Reusable Conv1D-BN-ReLU-Dropout-Pool block - <strong>Architecture</strong>: <div class="language-text highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a>Input [B, 1, 102400]  # Batch, Channels, Time samples
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>├─ ConvBlock1: Conv1D(1→32, k=64, s=4) → [B, 32, 25600]
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a>├─ ConvBlock2: Conv1D(32→64, k=32, s=2) → [B, 64, 12800]
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a>├─ ConvBlock3: Conv1D(64→128, k=16, s=2) → [B, 128, 6400]
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a>├─ ConvBlock4: Conv1D(128→256, k=8, s=2) → [B, 256, 3200]
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a>├─ ConvBlock5: Conv1D(256→512, k=4, s=2) → [B, 512, 1600]
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a>├─ GlobalAvgPool → [B, 512]
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>├─ FC1: 512 → 256, ReLU, Dropout(0.5)
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>└─ FC2: 256 → 11 (num_classes)
</span></code></pre></div> - <strong>Key Functions</strong>: - <code>forward(x)</code>: Forward pass - <code>get_intermediate_features(x, layer_name)</code>: Extract features at specific layer - <code>count_parameters()</code>: ~1.2M parameters - <strong>Hyperparameters</strong>: - Kernel sizes: [64, 32, 16, 8, 4] - Strides: [4, 2, 2, 2, 2] - Dropout: 0.5 - Batch normalization: After each conv layer - <strong>Dependencies</strong>: <code>torch.nn</code>, <code>models/base_model.py</code></p> <p><strong><code>models/cnn/conv_blocks.py</code></strong> - <strong>Purpose</strong>: Modular convolutional blocks for reusability - <strong>Key Classes</strong>: - <code>ConvBlock1D(nn.Module)</code>: Conv-BN-ReLU-Dropout-Pool - <code>ResidualConvBlock1D(nn.Module)</code>: Conv block with skip connection - <code>SeparableConv1D(nn.Module)</code>: Depthwise separable convolution (efficient) - <strong>Key Functions</strong>: - <code>forward(x)</code>: Standard forward pass - <strong>Design Rationale</strong>: - Modular blocks enable architecture search (Phase 4) - Residual blocks prevent gradient vanishing - Separable conv reduces parameters by ~9× - <strong>Dependencies</strong>: <code>torch.nn</code></p> <p><strong><code>models/cnn/attention_mechanisms.py</code></strong> - <strong>Purpose</strong>: Attention modules to focus on discriminative time regions - <strong>Key Classes</strong>: - <code>SelfAttention1D(nn.Module)</code>: Channel/spatial attention - <code>SEBlock(nn.Module)</code>: Squeeze-and-Excitation (recalibrate channels) - <code>CBAM(nn.Module)</code>: Convolutional Block Attention Module - <strong>Key Functions</strong>: - <code>forward(x)</code>: Attention-weighted features - <strong>Usage</strong>: Insert after conv layers: <code>x = attention_module(x)</code> - <strong>Benefit</strong>: +1-2% accuracy from report benchmarks - <strong>Dependencies</strong>: <code>torch.nn</code></p> <p><strong><code>models/cnn/pooling_layers.py</code></strong> - <strong>Purpose</strong>: Advanced pooling beyond MaxPool/AvgPool - <strong>Key Classes</strong>: - <code>AdaptiveAvgPool1D(nn.Module)</code>: Adaptive pooling to fixed output size - <code>StochasticPooling(nn.Module)</code>: Random sampling during training (regularization) - <code>AttentionPooling(nn.Module)</code>: Learnable weighted pooling - <strong>Key Functions</strong>: - <code>forward(x)</code>: Pooled output - <strong>Dependencies</strong>: <code>torch.nn</code></p> <p><strong><code>models/cnn/model_variants.py</code></strong> - <strong>Purpose</strong>: CNN architecture variations for experimentation - <strong>Key Classes</strong>: - <code>ShallowCNN(CNN1D)</code>: 3-layer lightweight (fast baseline) - <code>DeepCNN(CNN1D)</code>: 10-layer deep network - <code>WideResidualCNN(CNN1D)</code>: Wide layers with residual connections - <strong>Key Functions</strong>: - Same interface as <code>CNN1D.forward(x)</code> - <strong>Usage</strong>: <code>model = create_model('DeepCNN', config)</code> - <strong>Dependencies</strong>: <code>cnn_1d.py</code>, <code>conv_blocks.py</code></p> <h4 id=2-data-preprocessing-for-cnn-4-files><strong>2. Data Preprocessing for CNN (4 files)</strong><a class=headerlink href=#2-data-preprocessing-for-cnn-4-files title="Permanent link">&para;</a></h4> <p><strong><code>data/cnn_transforms.py</code></strong> - <strong>Purpose</strong>: Signal preprocessing specific to CNN input requirements - <strong>Key Classes</strong>: - <code>ToTensor1D(object)</code>: Convert NumPy array → torch.Tensor - <code>Normalize1D(object)</code>: Z-score normalization per sample - <code>RandomCrop1D(object)</code>: Extract random subsequence (data augmentation) - <code>RandomAmplitudeScale(object)</code>: Multiply by [0.8, 1.2] - <code>AddGaussianNoise(object)</code>: Inject noise with probability p - <strong>Key Functions</strong>: - <code>__call__(signal)</code>: Apply transformation - <strong>Dependencies</strong>: <code>torch</code>, <code>numpy</code></p> <p><strong><code>data/cnn_dataset.py</code></strong> - <strong>Purpose</strong>: PyTorch Dataset for CNN training (raw signals, no feature extraction) - <strong>Key Classes</strong>: - <code>RawSignalDataset(torch.utils.data.Dataset)</code>: Load signals directly - <strong>Key Functions</strong>: - <code>__getitem__(idx)</code>: Returns <code>(signal [1, T], label [int])</code> - <code>__len__()</code>: Dataset size - <strong>Difference from Phase 0</strong>: No feature extraction, returns raw waveforms - <strong>Dependencies</strong>: <code>torch.utils.data</code>, <code>data/dataset.py</code></p> <p><strong><code>data/cnn_dataloader.py</code></strong> - <strong>Purpose</strong>: Optimized DataLoaders for CNN training - <strong>Key Functions</strong>: - <code>create_cnn_dataloaders(dataset, config)</code>: Returns train/val/test loaders - <code>collate_fn(batch)</code>: Stack signals into batch tensor [B, 1, T] - <strong>Optimizations</strong>: - Pin memory: True (faster GPU transfer) - Num workers: 4 (parallel data loading) - Persistent workers: True (reduce initialization overhead) - <strong>Dependencies</strong>: <code>torch.utils.data</code>, <code>cnn_dataset.py</code></p> <p><strong><code>data/signal_augmentation.py</code></strong> - <strong>Purpose</strong>: Advanced augmentation techniques for CNNs - <strong>Key Classes</strong>: - <code>SignalAugmenter</code>: Orchestrates multiple augmentations - <strong>Key Functions</strong>: - <code>time_warp(signal, warp_factor)</code>: Non-linear time stretching - <code>frequency_mask(signal, fs, mask_param)</code>: Zero out frequency bands (SpecAugment-style) - <code>time_mask(signal, mask_param)</code>: Zero out time segments - <code>mixup(signal1, signal2, alpha=0.4)</code>: Convex combination of signals and labels - <strong>Benefit</strong>: +2-3% accuracy from data augmentation literature - <strong>Dependencies</strong>: <code>numpy</code>, <code>scipy.signal</code></p> <h4 id=3-cnn-training-infrastructure-5-files><strong>3. CNN Training Infrastructure (5 files)</strong><a class=headerlink href=#3-cnn-training-infrastructure-5-files title="Permanent link">&para;</a></h4> <p><strong><code>training/cnn_trainer.py</code></strong> - <strong>Purpose</strong>: CNN-specific training loop with optimizations - <strong>Key Classes</strong>: - <code>CNNTrainer(Trainer)</code>: Extends base trainer with CNN-specific logic - <strong>Key Functions</strong>: - <code>train_epoch(dataloader)</code>: Training loop with mixed precision - <code>validate_epoch(dataloader)</code>: Validation loop - <code>_compute_loss(outputs, targets)</code>: Cross-entropy with label smoothing - <code>_update_lr_scheduler(epoch)</code>: Cosine annealing schedule - <strong>Optimizations</strong>: - Mixed precision training (torch.cuda.amp) - Gradient clipping (max_norm=1.0) - Gradient accumulation for large effective batch size - <strong>Dependencies</strong>: <code>torch</code>, <code>training/trainer.py</code>, <code>training/losses.py</code></p> <p><strong><code>training/cnn_losses.py</code></strong> - <strong>Purpose</strong>: Loss functions tailored for CNN training - <strong>Key Classes</strong>: - <code>LabelSmoothingCrossEntropy(nn.Module)</code>: Regularization via soft labels - <code>FocalLoss(nn.Module)</code>: Address class imbalance (focus on hard examples) - <code>SupConLoss(nn.Module)</code>: Supervised contrastive loss (optional) - <strong>Key Functions</strong>: - <code>forward(logits, targets)</code>: Compute loss - <strong>Usage</strong>: <code>loss = LabelSmoothingCrossEntropy(smoothing=0.1)(logits, targets)</code> - <strong>Dependencies</strong>: <code>torch.nn</code></p> <p><strong><code>training/cnn_schedulers.py</code></strong> - <strong>Purpose</strong>: Learning rate schedules for CNN optimization - <strong>Key Functions</strong>: - <code>create_cosine_scheduler(optimizer, T_max, eta_min)</code>: Cosine annealing - <code>create_step_scheduler(optimizer, step_size, gamma)</code>: Step decay - <code>create_warmup_scheduler(optimizer, warmup_epochs)</code>: Linear warmup - <strong>Recommended</strong>: Warmup (5 epochs) → Cosine annealing (remaining epochs) - <strong>Dependencies</strong>: <code>torch.optim.lr_scheduler</code></p> <p><strong><code>training/cnn_callbacks.py</code></strong> - <strong>Purpose</strong>: Callbacks specific to CNN training - <strong>Key Classes</strong>: - <code>LearningRateMonitor(Callback)</code>: Log LR to MLflow - <code>GradientMonitor(Callback)</code>: Track gradient norms (detect vanishing/exploding) - <code>ActivationMonitor(Callback)</code>: Visualize layer activations - <strong>Key Functions</strong>: - <code>on_batch_end(batch, logs)</code>: Hook for monitoring - <strong>Dependencies</strong>: <code>training/callbacks.py</code>, <code>mlflow</code></p> <p><strong><code>training/cnn_optimizer.py</code></strong> - <strong>Purpose</strong>: Optimizer configurations for CNN - <strong>Key Functions</strong>: - <code>create_adam_optimizer(model_params, lr, weight_decay)</code>: Adam with decoupled weight decay (AdamW) - <code>create_sgd_optimizer(model_params, lr, momentum, nesterov)</code>: SGD with Nesterov momentum - <strong>Recommended</strong>: AdamW(lr=1e-3, weight_decay=1e-4) - <strong>Dependencies</strong>: <code>torch.optim</code></p> <h4 id=4-cnn-evaluation-4-files><strong>4. CNN Evaluation (4 files)</strong><a class=headerlink href=#4-cnn-evaluation-4-files title="Permanent link">&para;</a></h4> <p><strong><code>evaluation/cnn_evaluator.py</code></strong> - <strong>Purpose</strong>: Evaluate trained CNN on test set - <strong>Key Classes</strong>: - <code>CNNEvaluator(ModelEvaluator)</code>: Extends base evaluator - <strong>Key Functions</strong>: - <code>evaluate(model, test_loader)</code>: Full evaluation - <code>compute_per_class_metrics(preds, targets)</code>: Precision/recall/F1 per class - <code>generate_classification_report()</code>: Summary report - <strong>Additional Metrics</strong>: - Inference time per sample - GPU memory usage - FLOPs count - <strong>Dependencies</strong>: <code>evaluation/evaluator.py</code>, <code>torch</code></p> <p><strong><code>evaluation/cnn_interpretability.py</code></strong> - <strong>Purpose</strong>: Explain CNN predictions (address black-box concern) - <strong>Key Classes</strong>: - <code>GradCAM1D</code>: Gradient-weighted Class Activation Mapping for 1D signals - <code>IntegratedGradients1D</code>: Attribution method - <strong>Key Functions</strong>: - <code>generate_gradcam(model, signal, target_class)</code>: Heatmap of important regions - <code>generate_attribution_map(model, signal, target_class)</code>: Pixel-level importance - <strong>Usage</strong>: Visualize which time regions contribute to fault classification - <strong>Dependencies</strong>: <code>torch</code>, <code>captum</code> (PyTorch interpretability library)</p> <p><strong><code>evaluation/cnn_robustness.py</code></strong> - <strong>Purpose</strong>: Robustness testing specific to CNN (beyond classical tests) - <strong>Key Functions</strong>: - <code>test_adversarial_robustness(model, test_loader, epsilon)</code>: FGSM attacks - <code>test_input_corruption(model, test_loader, corruption_types)</code>: Blur, noise, etc. - <strong>Corruption Types</strong>: - Gaussian noise - Impulse noise - Shot noise (Poisson) - Motion blur (simulated sensor vibration) - <strong>Dependencies</strong>: <code>evaluation/robustness_tester.py</code>, <code>torch</code></p> <p><strong><code>evaluation/cnn_visualization.py</code></strong> - <strong>Purpose</strong>: Visualize CNN internals - <strong>Key Functions</strong>: - <code>plot_feature_maps(model, signal, layer_name)</code>: Visualize conv layer activations - <code>plot_filters(model, layer_name)</code>: Visualize learned conv filters - <code>plot_training_curves(history)</code>: Loss/accuracy over epochs - <strong>Dependencies</strong>: <code>matplotlib</code>, <code>torch</code></p> <h4 id=5-experiment-management-3-files><strong>5. Experiment Management (3 files)</strong><a class=headerlink href=#5-experiment-management-3-files title="Permanent link">&para;</a></h4> <p><strong><code>experiments/cnn_experiment.py</code></strong> - <strong>Purpose</strong>: Orchestrate full CNN training experiment - <strong>Key Classes</strong>: - <code>CNNExperiment</code>: Manages experiment lifecycle - <strong>Key Functions</strong>: - <code>setup_experiment(config)</code>: Initialize model, data, trainer - <code>run_training()</code>: Train model - <code>run_evaluation()</code>: Evaluate on test set - <code>log_results_to_mlflow()</code>: Log metrics, artifacts - <strong>Dependencies</strong>: <code>mlflow</code>, <code>training/cnn_trainer.py</code>, <code>evaluation/cnn_evaluator.py</code></p> <p><strong><code>experiments/cnn_hparam_search.py</code></strong> - <strong>Purpose</strong>: Hyperparameter search for CNN - <strong>Key Functions</strong>: - <code>run_hyperparameter_search(config, n_trials)</code>: Optuna-based tuning - <code>objective(trial)</code>: Define search space - <strong>Search Space</strong>: - Learning rate: [1e-4, 1e-2] (log scale) - Batch size: [16, 32, 64, 128] - Dropout: [0.3, 0.5, 0.7] - Weight decay: [1e-5, 1e-3] (log scale) - Number of conv layers: [4, 6, 8] - <strong>Dependencies</strong>: <code>optuna</code>, <code>experiments/cnn_experiment.py</code></p> <p><strong><code>experiments/cnn_ablation_study.py</code></strong> - <strong>Purpose</strong>: Ablation studies to understand component contributions - <strong>Key Functions</strong>: - <code>ablate_data_augmentation(config)</code>: Train with/without augmentation - <code>ablate_batch_normalization(config)</code>: Remove BN layers - <code>ablate_dropout(config)</code>: Train without dropout - <code>ablate_attention(config)</code>: Remove attention modules - <strong>Output</strong>: Table showing impact of each component (e.g., "-2.1% accuracy without BN") - <strong>Dependencies</strong>: <code>experiments/cnn_experiment.py</code></p> <h4 id=6-utilities-3-files><strong>6. Utilities (3 files)</strong><a class=headerlink href=#6-utilities-3-files title="Permanent link">&para;</a></h4> <p><strong><code>utils/cnn_utils.py</code></strong> - <strong>Purpose</strong>: Helper functions for CNN development - <strong>Key Functions</strong>: - <code>count_parameters(model)</code>: Total trainable parameters - <code>compute_flops(model, input_size)</code>: Computational cost - <code>visualize_model_architecture(model)</code>: Generate architecture diagram - <strong>Dependencies</strong>: <code>torch</code>, <code>torchsummary</code></p> <p><strong><code>utils/checkpoint_manager.py</code></strong> - <strong>Purpose</strong>: Manage model checkpoints during training - <strong>Key Classes</strong>: - <code>CheckpointManager</code>: Save/load best models - <strong>Key Functions</strong>: - <code>save_checkpoint(model, optimizer, epoch, metrics)</code>: Save state dict - <code>load_checkpoint(checkpoint_path)</code>: Restore training state - <code>save_best_model(model, metric, threshold)</code>: Save if metric improves - <strong>Dependencies</strong>: <code>torch</code>, <code>pathlib</code></p> <p><strong><code>utils/early_stopping.py</code></strong> - <strong>Purpose</strong>: Early stopping to prevent overfitting - <strong>Key Classes</strong>: - <code>EarlyStopping</code>: Monitor validation loss - <strong>Key Functions</strong>: - <code>should_stop(val_loss)</code>: Returns True if patience exceeded - <strong>Parameters</strong>: patience=10, min_delta=0.001 - <strong>Dependencies</strong>: None (pure Python)</p> <h3 id=architecture-decisions>Architecture Decisions<a class=headerlink href=#architecture-decisions title="Permanent link">&para;</a></h3> <p><strong>1. 1D Convolution vs. 2D Convolution (Spectrogram)</strong> - <strong>Decision</strong>: Use 1D convolution on raw signals - <strong>Rationale</strong>: - More parameter-efficient (1D kernels vs. 2D) - Directly learns from waveform (no hand-crafted spectrogram) - Faster training (no STFT computation per sample) - <strong>Alternative Considered</strong>: 2D CNN on spectrograms (Phase 3 explores this)</p> <p><strong>2. Large Receptive Field via Strided Convolutions</strong> - <strong>Decision</strong>: Use stride 4 in first layer, stride 2 thereafter - <strong>Rationale</strong>: - Input is 102,400 samples (5 sec × 20.48 kHz) - Need to downsample quickly to manageable size - Large strides increase receptive field - <strong>Trade-off</strong>: Some aliasing, but acceptable for fault diagnosis</p> <p><strong>3. Global Average Pooling Instead of Flatten</strong> - <strong>Decision</strong>: Use AdaptiveAvgPool1D before FC layers - <strong>Rationale</strong>: - Reduces overfitting (fewer parameters in FC layer) - Invariant to small input size changes - Standard in modern CNNs (ResNet, EfficientNet)</p> <p><strong>4. Batch Normalization After Every Conv Layer</strong> - <strong>Decision</strong>: Conv → BN → ReLU (not Conv → ReLU → BN) - <strong>Rationale</strong>: - BN before activation is standard practice - Stabilizes training (allows higher learning rates) - Reduces internal covariate shift</p> <p><strong>5. Label Smoothing for Regularization</strong> - <strong>Decision</strong>: Use smoothing factor ε = 0.1 - <strong>Rationale</strong>: - Prevents overconfident predictions - Improves calibration (ECE in report was 0.1267, want to reduce) - Negligible accuracy cost (&lt; 0.5%) from literature</p> <p><strong>6. Mixed Precision Training</strong> - <strong>Decision</strong>: Use torch.cuda.amp for FP16 training - <strong>Rationale</strong>: - 2-3× speedup on modern GPUs (Tensor Cores) - Reduces memory usage (allows larger batches) - Numerical stability with gradient scaling - <strong>Requirement</strong>: CUDA-capable GPU (RTX 20xx+, V100, A100)</p> <h3 id=data-flow>Data Flow<a class=headerlink href=#data-flow title="Permanent link">&para;</a></h3> <div class="language-text highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>┌────────────────────────────────────────────────────────────┐
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a>│              CNN TRAINING PIPELINE (Phase 2)                │
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>└────────────────────────────────────────────────────────────┘
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a>1. DATA LOADING
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a>   ┌──────────────────────────────────────────────────────┐
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a>   │ data/cnn_dataset.py (RawSignalDataset)               │
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a>   │  ├─ Load signals from HDF5 cache (Phase 0 output)   │
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a>   │  ├─ No feature extraction (raw waveforms)            │
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a>   │  └─ Apply transforms (normalize, augment)            │
</span><span id=__span-1-11><a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a>   │         ↓                                             │
</span><span id=__span-1-12><a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a>   │ data/cnn_dataloader.py                                │
</span><span id=__span-1-13><a id=__codelineno-1-13 name=__codelineno-1-13 href=#__codelineno-1-13></a>   │  ├─ Batch signals: [B, 1, 102400]                   │
</span><span id=__span-1-14><a id=__codelineno-1-14 name=__codelineno-1-14 href=#__codelineno-1-14></a>   │  ├─ Pin memory for fast GPU transfer                │
</span><span id=__span-1-15><a id=__codelineno-1-15 name=__codelineno-1-15 href=#__codelineno-1-15></a>   │  └─ Parallel loading (num_workers=4)                 │
</span><span id=__span-1-16><a id=__codelineno-1-16 name=__codelineno-1-16 href=#__codelineno-1-16></a>   └──────────────────────────────────────────────────────┘
</span><span id=__span-1-17><a id=__codelineno-1-17 name=__codelineno-1-17 href=#__codelineno-1-17></a>                        ↓
</span><span id=__span-1-18><a id=__codelineno-1-18 name=__codelineno-1-18 href=#__codelineno-1-18></a>
</span><span id=__span-1-19><a id=__codelineno-1-19 name=__codelineno-1-19 href=#__codelineno-1-19></a>2. MODEL FORWARD PASS
</span><span id=__span-1-20><a id=__codelineno-1-20 name=__codelineno-1-20 href=#__codelineno-1-20></a>   ┌──────────────────────────────────────────────────────┐
</span><span id=__span-1-21><a id=__codelineno-1-21 name=__codelineno-1-21 href=#__codelineno-1-21></a>   │ models/cnn/cnn_1d.py                                  │
</span><span id=__span-1-22><a id=__codelineno-1-22 name=__codelineno-1-22 href=#__codelineno-1-22></a>   │                                                       │
</span><span id=__span-1-23><a id=__codelineno-1-23 name=__codelineno-1-23 href=#__codelineno-1-23></a>   │ Input: [B, 1, 102400]                                 │
</span><span id=__span-1-24><a id=__codelineno-1-24 name=__codelineno-1-24 href=#__codelineno-1-24></a>   │  ↓                                                    │
</span><span id=__span-1-25><a id=__codelineno-1-25 name=__codelineno-1-25 href=#__codelineno-1-25></a>   │ ConvBlock1: [B, 32, 25600]  (k=64, s=4)             │
</span><span id=__span-1-26><a id=__codelineno-1-26 name=__codelineno-1-26 href=#__codelineno-1-26></a>   │  ↓                                                    │
</span><span id=__span-1-27><a id=__codelineno-1-27 name=__codelineno-1-27 href=#__codelineno-1-27></a>   │ ConvBlock2: [B, 64, 12800]  (k=32, s=2)             │
</span><span id=__span-1-28><a id=__codelineno-1-28 name=__codelineno-1-28 href=#__codelineno-1-28></a>   │  ↓                                                    │
</span><span id=__span-1-29><a id=__codelineno-1-29 name=__codelineno-1-29 href=#__codelineno-1-29></a>   │ ConvBlock3: [B, 128, 6400]  (k=16, s=2)             │
</span><span id=__span-1-30><a id=__codelineno-1-30 name=__codelineno-1-30 href=#__codelineno-1-30></a>   │  ↓                                                    │
</span><span id=__span-1-31><a id=__codelineno-1-31 name=__codelineno-1-31 href=#__codelineno-1-31></a>   │ ConvBlock4: [B, 256, 3200]  (k=8, s=2)              │
</span><span id=__span-1-32><a id=__codelineno-1-32 name=__codelineno-1-32 href=#__codelineno-1-32></a>   │  ↓                                                    │
</span><span id=__span-1-33><a id=__codelineno-1-33 name=__codelineno-1-33 href=#__codelineno-1-33></a>   │ ConvBlock5: [B, 512, 1600]  (k=4, s=2)              │
</span><span id=__span-1-34><a id=__codelineno-1-34 name=__codelineno-1-34 href=#__codelineno-1-34></a>   │  ↓                                                    │
</span><span id=__span-1-35><a id=__codelineno-1-35 name=__codelineno-1-35 href=#__codelineno-1-35></a>   │ GlobalAvgPool: [B, 512]                              │
</span><span id=__span-1-36><a id=__codelineno-1-36 name=__codelineno-1-36 href=#__codelineno-1-36></a>   │  ↓                                                    │
</span><span id=__span-1-37><a id=__codelineno-1-37 name=__codelineno-1-37 href=#__codelineno-1-37></a>   │ FC1: [B, 256] + ReLU + Dropout(0.5)                 │
</span><span id=__span-1-38><a id=__codelineno-1-38 name=__codelineno-1-38 href=#__codelineno-1-38></a>   │  ↓                                                    │
</span><span id=__span-1-39><a id=__codelineno-1-39 name=__codelineno-1-39 href=#__codelineno-1-39></a>   │ FC2: [B, 11] (logits)                                │
</span><span id=__span-1-40><a id=__codelineno-1-40 name=__codelineno-1-40 href=#__codelineno-1-40></a>   │         ↓                                             │
</span><span id=__span-1-41><a id=__codelineno-1-41 name=__codelineno-1-41 href=#__codelineno-1-41></a>   │ Output: Logits [B, 11]                                │
</span><span id=__span-1-42><a id=__codelineno-1-42 name=__codelineno-1-42 href=#__codelineno-1-42></a>   └──────────────────────────────────────────────────────┘
</span><span id=__span-1-43><a id=__codelineno-1-43 name=__codelineno-1-43 href=#__codelineno-1-43></a>                        ↓
</span><span id=__span-1-44><a id=__codelineno-1-44 name=__codelineno-1-44 href=#__codelineno-1-44></a>
</span><span id=__span-1-45><a id=__codelineno-1-45 name=__codelineno-1-45 href=#__codelineno-1-45></a>3. LOSS COMPUTATION
</span><span id=__span-1-46><a id=__codelineno-1-46 name=__codelineno-1-46 href=#__codelineno-1-46></a>   ┌──────────────────────────────────────────────────────┐
</span><span id=__span-1-47><a id=__codelineno-1-47 name=__codelineno-1-47 href=#__codelineno-1-47></a>   │ training/cnn_losses.py                                │
</span><span id=__span-1-48><a id=__codelineno-1-48 name=__codelineno-1-48 href=#__codelineno-1-48></a>   │  ├─ LabelSmoothingCrossEntropy(logits, targets)     │
</span><span id=__span-1-49><a id=__codelineno-1-49 name=__codelineno-1-49 href=#__codelineno-1-49></a>   │  └─ Loss: scalar                                     │
</span><span id=__span-1-50><a id=__codelineno-1-50 name=__codelineno-1-50 href=#__codelineno-1-50></a>   └──────────────────────────────────────────────────────┘
</span><span id=__span-1-51><a id=__codelineno-1-51 name=__codelineno-1-51 href=#__codelineno-1-51></a>                        ↓
</span><span id=__span-1-52><a id=__codelineno-1-52 name=__codelineno-1-52 href=#__codelineno-1-52></a>
</span><span id=__span-1-53><a id=__codelineno-1-53 name=__codelineno-1-53 href=#__codelineno-1-53></a>4. BACKPROPAGATION
</span><span id=__span-1-54><a id=__codelineno-1-54 name=__codelineno-1-54 href=#__codelineno-1-54></a>   ┌──────────────────────────────────────────────────────┐
</span><span id=__span-1-55><a id=__codelineno-1-55 name=__codelineno-1-55 href=#__codelineno-1-55></a>   │ training/cnn_trainer.py                               │
</span><span id=__span-1-56><a id=__codelineno-1-56 name=__codelineno-1-56 href=#__codelineno-1-56></a>   │  ├─ Scaled backward pass (mixed precision)          │
</span><span id=__span-1-57><a id=__codelineno-1-57 name=__codelineno-1-57 href=#__codelineno-1-57></a>   │  ├─ Gradient clipping (max_norm=1.0)                │
</span><span id=__span-1-58><a id=__codelineno-1-58 name=__codelineno-1-58 href=#__codelineno-1-58></a>   │  ├─ Optimizer step (AdamW)                           │
</span><span id=__span-1-59><a id=__codelineno-1-59 name=__codelineno-1-59 href=#__codelineno-1-59></a>   │  └─ LR scheduler step (Cosine annealing)            │
</span><span id=__span-1-60><a id=__codelineno-1-60 name=__codelineno-1-60 href=#__codelineno-1-60></a>   └──────────────────────────────────────────────────────┘
</span><span id=__span-1-61><a id=__codelineno-1-61 name=__codelineno-1-61 href=#__codelineno-1-61></a>                        ↓
</span><span id=__span-1-62><a id=__codelineno-1-62 name=__codelineno-1-62 href=#__codelineno-1-62></a>
</span><span id=__span-1-63><a id=__codelineno-1-63 name=__codelineno-1-63 href=#__codelineno-1-63></a>5. VALIDATION LOOP (every N epochs)
</span><span id=__span-1-64><a id=__codelineno-1-64 name=__codelineno-1-64 href=#__codelineno-1-64></a>   ┌──────────────────────────────────────────────────────┐
</span><span id=__span-1-65><a id=__codelineno-1-65 name=__codelineno-1-65 href=#__codelineno-1-65></a>   │ training/cnn_trainer.py                               │
</span><span id=__span-1-66><a id=__codelineno-1-66 name=__codelineno-1-66 href=#__codelineno-1-66></a>   │  ├─ Forward pass on validation set (no grad)        │
</span><span id=__span-1-67><a id=__codelineno-1-67 name=__codelineno-1-67 href=#__codelineno-1-67></a>   │  ├─ Compute validation loss, accuracy               │
</span><span id=__span-1-68><a id=__codelineno-1-68 name=__codelineno-1-68 href=#__codelineno-1-68></a>   │  └─ Trigger callbacks (checkpoint, early stop)      │
</span><span id=__span-1-69><a id=__codelineno-1-69 name=__codelineno-1-69 href=#__codelineno-1-69></a>   └──────────────────────────────────────────────────────┘
</span><span id=__span-1-70><a id=__codelineno-1-70 name=__codelineno-1-70 href=#__codelineno-1-70></a>                        ↓
</span><span id=__span-1-71><a id=__codelineno-1-71 name=__codelineno-1-71 href=#__codelineno-1-71></a>
</span><span id=__span-1-72><a id=__codelineno-1-72 name=__codelineno-1-72 href=#__codelineno-1-72></a>6. EXPERIMENT LOGGING
</span><span id=__span-1-73><a id=__codelineno-1-73 name=__codelineno-1-73 href=#__codelineno-1-73></a>   ┌──────────────────────────────────────────────────────┐
</span><span id=__span-1-74><a id=__codelineno-1-74 name=__codelineno-1-74 href=#__codelineno-1-74></a>   │ experiments/experiment_manager.py (MLflow)            │
</span><span id=__span-1-75><a id=__codelineno-1-75 name=__codelineno-1-75 href=#__codelineno-1-75></a>   │  ├─ Log epoch metrics (loss, accuracy)              │
</span><span id=__span-1-76><a id=__codelineno-1-76 name=__codelineno-1-76 href=#__codelineno-1-76></a>   │  ├─ Log learning rate                                │
</span><span id=__span-1-77><a id=__codelineno-1-77 name=__codelineno-1-77 href=#__codelineno-1-77></a>   │  ├─ Log hyperparameters                              │
</span><span id=__span-1-78><a id=__codelineno-1-78 name=__codelineno-1-78 href=#__codelineno-1-78></a>   │  └─ Save model checkpoint                            │
</span><span id=__span-1-79><a id=__codelineno-1-79 name=__codelineno-1-79 href=#__codelineno-1-79></a>   └──────────────────────────────────────────────────────┘
</span><span id=__span-1-80><a id=__codelineno-1-80 name=__codelineno-1-80 href=#__codelineno-1-80></a>                        ↓
</span><span id=__span-1-81><a id=__codelineno-1-81 name=__codelineno-1-81 href=#__codelineno-1-81></a>
</span><span id=__span-1-82><a id=__codelineno-1-82 name=__codelineno-1-82 href=#__codelineno-1-82></a>7. FINAL EVALUATION
</span><span id=__span-1-83><a id=__codelineno-1-83 name=__codelineno-1-83 href=#__codelineno-1-83></a>   ┌──────────────────────────────────────────────────────┐
</span><span id=__span-1-84><a id=__codelineno-1-84 name=__codelineno-1-84 href=#__codelineno-1-84></a>   │ evaluation/cnn_evaluator.py                           │
</span><span id=__span-1-85><a id=__codelineno-1-85 name=__codelineno-1-85 href=#__codelineno-1-85></a>   │  ├─ Load best checkpoint                             │
</span><span id=__span-1-86><a id=__codelineno-1-86 name=__codelineno-1-86 href=#__codelineno-1-86></a>   │  ├─ Predict on test set                              │
</span><span id=__span-1-87><a id=__codelineno-1-87 name=__codelineno-1-87 href=#__codelineno-1-87></a>   │  ├─ Compute metrics (accuracy, F1, confusion matrix) │
</span><span id=__span-1-88><a id=__codelineno-1-88 name=__codelineno-1-88 href=#__codelineno-1-88></a>   │  └─ Generate classification report                   │
</span><span id=__span-1-89><a id=__codelineno-1-89 name=__codelineno-1-89 href=#__codelineno-1-89></a>   │         ↓                                             │
</span><span id=__span-1-90><a id=__codelineno-1-90 name=__codelineno-1-90 href=#__codelineno-1-90></a>   │ Output: Test accuracy, per-class metrics             │
</span><span id=__span-1-91><a id=__codelineno-1-91 name=__codelineno-1-91 href=#__codelineno-1-91></a>   │         Confusion matrix, ROC curves                 │
</span><span id=__span-1-92><a id=__codelineno-1-92 name=__codelineno-1-92 href=#__codelineno-1-92></a>   └──────────────────────────────────────────────────────┘
</span></code></pre></div> <h3 id=integration-points>Integration Points<a class=headerlink href=#integration-points title="Permanent link">&para;</a></h3> <p><strong>1. With Phase 0 (Data Infrastructure)</strong> - <strong>Input</strong>: Signals from <code>data/cache_manager.py</code> (HDF5 cache) - <strong>Interface</strong>: <code>RawSignalDataset</code> loads signals without feature extraction - <strong>Difference</strong>: Phase 1 used extracted features, Phase 2 uses raw signals</p> <p><strong>2. With Phase 1 (Classical ML Baseline)</strong> - <strong>Comparison</strong>: Benchmark CNN vs. Random Forest (Phase 1 best: 95.33%) - <strong>Target</strong>: Match or exceed classical ML accuracy - <strong>Visualization</strong>: Side-by-side confusion matrices, ROC curves</p> <p><strong>3. With Future Phases</strong> - <strong>Phase 3</strong>: CNN features serve as input to Transformer - <strong>Phase 6</strong>: CNN backbone used in hybrid physics-informed models - <strong>Phase 8</strong>: CNN predictions combined in ensemble</p> <p><strong>4. With MLflow</strong> - <strong>Logging</strong>: All CNN experiments tracked in MLflow - <strong>Artifacts</strong>: Model checkpoints, training curves, confusion matrices - <strong>Comparison</strong>: Compare CNN variants (shallow vs. deep, with/without attention)</p> <h3 id=testing-strategy>Testing Strategy<a class=headerlink href=#testing-strategy title="Permanent link">&para;</a></h3> <p><strong>1. Unit Tests</strong></p> <p><strong><code>tests/test_cnn_model.py</code></strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=k>def</span><span class=w> </span><span class=nf>test_cnn_forward_pass</span><span class=p>():</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Test CNN forward pass with dummy input.&quot;&quot;&quot;</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>CNN1D</span><span class=p>(</span><span class=n>num_classes</span><span class=o>=</span><span class=mi>11</span><span class=p>)</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a>    <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>102400</span><span class=p>)</span>  <span class=c1># Batch of 2 signals</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a>    <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a>    <span class=k>assert</span> <span class=n>output</span><span class=o>.</span><span class=n>shape</span> <span class=o>==</span> <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>11</span><span class=p>),</span> <span class=s2>&quot;Output shape mismatch&quot;</span>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a><span class=k>def</span><span class=w> </span><span class=nf>test_cnn_gradient_flow</span><span class=p>():</span>
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Ensure gradients flow through all layers.&quot;&quot;&quot;</span>
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>CNN1D</span><span class=p>(</span><span class=n>num_classes</span><span class=o>=</span><span class=mi>11</span><span class=p>)</span>
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a>    <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>102400</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a>    <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span><span id=__span-2-13><a id=__codelineno-2-13 name=__codelineno-2-13 href=#__codelineno-2-13></a>    <span class=n>loss</span> <span class=o>=</span> <span class=n>output</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
</span><span id=__span-2-14><a id=__codelineno-2-14 name=__codelineno-2-14 href=#__codelineno-2-14></a>    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-2-15><a id=__codelineno-2-15 name=__codelineno-2-15 href=#__codelineno-2-15></a>    <span class=c1># Check input gradient computed</span>
</span><span id=__span-2-16><a id=__codelineno-2-16 name=__codelineno-2-16 href=#__codelineno-2-16></a>    <span class=k>assert</span> <span class=n>x</span><span class=o>.</span><span class=n>grad</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span>
</span></code></pre></div></p> <p><strong><code>tests/test_cnn_transforms.py</code></strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=k>def</span><span class=w> </span><span class=nf>test_random_crop</span><span class=p>():</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Test random crop augmentation.&quot;&quot;&quot;</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a>    <span class=n>signal</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>102400</span><span class=p>)</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a>    <span class=n>transform</span> <span class=o>=</span> <span class=n>RandomCrop1D</span><span class=p>(</span><span class=n>crop_size</span><span class=o>=</span><span class=mi>10000</span><span class=p>)</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a>    <span class=n>cropped</span> <span class=o>=</span> <span class=n>transform</span><span class=p>(</span><span class=n>signal</span><span class=p>)</span>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a>    <span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>cropped</span><span class=p>)</span> <span class=o>==</span> <span class=mi>10000</span>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a><span class=k>def</span><span class=w> </span><span class=nf>test_mixup</span><span class=p>():</span>
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Test mixup augmentation.&quot;&quot;&quot;</span>
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a>    <span class=n>signal1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=mi>1000</span><span class=p>)</span>
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a>    <span class=n>signal2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=mi>1000</span><span class=p>)</span>
</span><span id=__span-3-12><a id=__codelineno-3-12 name=__codelineno-3-12 href=#__codelineno-3-12></a>    <span class=n>mixed</span><span class=p>,</span> <span class=n>lambda_</span> <span class=o>=</span> <span class=n>mixup</span><span class=p>(</span><span class=n>signal1</span><span class=p>,</span> <span class=n>signal2</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.4</span><span class=p>)</span>
</span><span id=__span-3-13><a id=__codelineno-3-13 name=__codelineno-3-13 href=#__codelineno-3-13></a>    <span class=c1># Mixed signal should be between 0 and 1</span>
</span><span id=__span-3-14><a id=__codelineno-3-14 name=__codelineno-3-14 href=#__codelineno-3-14></a>    <span class=k>assert</span> <span class=mi>0</span> <span class=o>&lt;=</span> <span class=n>mixed</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span> <span class=o>&lt;=</span> <span class=mi>1</span>
</span></code></pre></div></p> <p><strong>2. Integration Tests</strong></p> <p><strong><code>tests/test_cnn_training.py</code></strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=k>def</span><span class=w> </span><span class=nf>test_cnn_training_loop</span><span class=p>():</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Test full training loop runs without errors.&quot;&quot;&quot;</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a>    <span class=c1># Small dummy dataset</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a>    <span class=n>dataset</span> <span class=o>=</span> <span class=n>DummyBearingDataset</span><span class=p>(</span><span class=n>n_samples</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a>    <span class=n>train_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>8</span><span class=p>)</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a>    <span class=c1># Model and trainer</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>CNN1D</span><span class=p>(</span><span class=n>num_classes</span><span class=o>=</span><span class=mi>11</span><span class=p>)</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a>    <span class=n>trainer</span> <span class=o>=</span> <span class=n>CNNTrainer</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>config</span><span class=p>)</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a>    <span class=c1># Train for 2 epochs</span>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a>    <span class=n>trainer</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>num_epochs</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>train_loader</span><span class=o>=</span><span class=n>train_loader</span><span class=p>)</span>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a>
</span><span id=__span-4-14><a id=__codelineno-4-14 name=__codelineno-4-14 href=#__codelineno-4-14></a>    <span class=c1># Check model trained</span>
</span><span id=__span-4-15><a id=__codelineno-4-15 name=__codelineno-4-15 href=#__codelineno-4-15></a>    <span class=k>assert</span> <span class=n>trainer</span><span class=o>.</span><span class=n>epoch</span> <span class=o>==</span> <span class=mi>2</span>
</span></code></pre></div></p> <p><strong>3. Convergence Tests</strong></p> <p><strong><code>tests/test_cnn_convergence.py</code></strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=k>def</span><span class=w> </span><span class=nf>test_cnn_overfits_small_dataset</span><span class=p>():</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Ensure CNN can overfit (sanity check).&quot;&quot;&quot;</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a>    <span class=c1># Tiny dataset (10 samples)</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a>    <span class=n>dataset</span> <span class=o>=</span> <span class=n>DummyBearingDataset</span><span class=p>(</span><span class=n>n_samples</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a>    <span class=n>train_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>CNN1D</span><span class=p>(</span><span class=n>num_classes</span><span class=o>=</span><span class=mi>11</span><span class=p>)</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a>    <span class=n>trainer</span> <span class=o>=</span> <span class=n>CNNTrainer</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>config</span><span class=p>)</span>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a>    <span class=c1># Train until convergence</span>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a>    <span class=n>trainer</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>num_epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>train_loader</span><span class=o>=</span><span class=n>train_loader</span><span class=p>)</span>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a>
</span><span id=__span-5-13><a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a>    <span class=c1># Should achieve 100% training accuracy</span>
</span><span id=__span-5-14><a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a>    <span class=n>train_acc</span> <span class=o>=</span> <span class=n>trainer</span><span class=o>.</span><span class=n>evaluate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>)</span>
</span><span id=__span-5-15><a id=__codelineno-5-15 name=__codelineno-5-15 href=#__codelineno-5-15></a>    <span class=k>assert</span> <span class=n>train_acc</span> <span class=o>&gt;</span> <span class=mf>0.99</span><span class=p>,</span> <span class=s2>&quot;Model failed to overfit small dataset&quot;</span>
</span></code></pre></div></p> <p><strong>4. Comparison Tests</strong></p> <p><strong><code>tests/test_cnn_vs_classical.py</code></strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=k>def</span><span class=w> </span><span class=nf>test_cnn_matches_classical_baseline</span><span class=p>():</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Ensure CNN achieves similar accuracy to classical ML.&quot;&quot;&quot;</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>    <span class=c1># Load standard test set</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a>    <span class=n>test_dataset</span> <span class=o>=</span> <span class=n>load_standard_test_set</span><span class=p>()</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>    <span class=n>test_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>test_dataset</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>)</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a>    <span class=c1># Load trained CNN</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>    <span class=n>cnn_model</span> <span class=o>=</span> <span class=n>load_best_cnn_checkpoint</span><span class=p>()</span>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a>    <span class=n>cnn_accuracy</span> <span class=o>=</span> <span class=n>evaluate_model</span><span class=p>(</span><span class=n>cnn_model</span><span class=p>,</span> <span class=n>test_loader</span><span class=p>)</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a>    <span class=c1># Compare to classical baseline (95.33% from Phase 1)</span>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a>    <span class=n>classical_accuracy</span> <span class=o>=</span> <span class=mf>0.9533</span>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a>    <span class=c1># Allow 3% margin (92.33% minimum)</span>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a>    <span class=k>assert</span> <span class=n>cnn_accuracy</span> <span class=o>&gt;=</span> <span class=mf>0.9233</span><span class=p>,</span> \
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a>        <span class=sa>f</span><span class=s2>&quot;CNN accuracy (</span><span class=si>{</span><span class=n>cnn_accuracy</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>) below acceptable threshold&quot;</span>
</span></code></pre></div></p> <h3 id=acceptance-criteria>Acceptance Criteria<a class=headerlink href=#acceptance-criteria title="Permanent link">&para;</a></h3> <p><strong>Phase 2 Complete When:</strong></p> <p>✅ <strong>CNN model trains successfully</strong> - Forward pass completes without errors - Backward pass computes gradients correctly - Model converges on training set (&gt; 95% train accuracy after 50 epochs)</p> <p>✅ <strong>Achieves target accuracy on test set</strong> - <strong>Minimum</strong>: 93% test accuracy (within 2.5% of classical baseline) - <strong>Target</strong>: 95% test accuracy (matches classical ML) - <strong>Stretch Goal</strong>: 97% test accuracy (surpasses classical ML)</p> <p>✅ <strong>Per-class performance acceptable</strong> - Per-class recall ≥ 85% for at least 9/11 classes - Mixed fault classes (challenge cases from Phase 1) improved accuracy</p> <p>✅ <strong>Training efficiency acceptable</strong> - Training time: &lt; 2 hours for 100 epochs on single GPU (RTX 3080 or better) - Inference time: &lt; 50 ms per sample (faster than 100ms required for deployment) - GPU memory usage: &lt; 8 GB (fits on consumer GPUs)</p> <p>✅ <strong>Robustness comparable to classical ML</strong> - Sensor noise test: accuracy drop ≤ 20% (vs. 16.82% for classical ML) - Missing features test: N/A for end-to-end models (different paradigm) - Temporal drift test: accuracy drop ≤ 5% - Adversarial robustness: &lt; 10% accuracy drop under FGSM attack (ε=0.1)</p> <p>✅ <strong>Interpretability demonstrated</strong> - Grad-CAM visualizations show CNN focuses on fault-relevant time regions - Activation visualizations confirm hierarchical feature learning - Can explain misclassifications with attribution maps</p> <p>✅ <strong>Reproducibility validated</strong> - Same hyperparameters → same accuracy (±0.5%) - Saved checkpoint loads correctly and reproduces results - Config file alone sufficient to reproduce experiment</p> <p>✅ <strong>Comparison with classical ML documented</strong> - Side-by-side confusion matrix comparison (CNN vs. Random Forest) - Accuracy comparison table across all 11 classes - Error analysis: Which faults does CNN handle better/worse?</p> <p>✅ <strong>MLflow logging functional</strong> - All experiments tracked with hyperparameters - Training curves (loss, accuracy) logged every epoch - Best model checkpoint saved as artifact - Confusion matrix, ROC curves saved as images</p> <p>✅ <strong>Documentation complete</strong> - README explaining CNN architecture choices - Jupyter notebook demonstrating CNN training from scratch - API documentation for all CNN modules</p> <h3 id=estimated-effort>Estimated Effort<a class=headerlink href=#estimated-effort title="Permanent link">&para;</a></h3> <p><strong>Time Breakdown:</strong> - CNN architecture (5 files): 4 days - <code>cnn_1d.py</code>: 1 day (core architecture) - <code>conv_blocks.py</code>: 1 day (modular blocks) - <code>attention_mechanisms.py</code>: 1 day (SE, CBAM modules) - <code>pooling_layers.py</code>: 0.5 days - <code>model_variants.py</code>: 0.5 days</p> <ul> <li>Data preprocessing (4 files): 2 days</li> <li><code>cnn_transforms.py</code>: 1 day</li> <li><code>cnn_dataset.py</code>: 0.5 days</li> <li><code>cnn_dataloader.py</code>: 0.25 days</li> <li> <p><code>signal_augmentation.py</code>: 0.25 days</p> </li> <li> <p>Training infrastructure (5 files): 3 days</p> </li> <li><code>cnn_trainer.py</code>: 1 day (mixed precision, gradient clipping)</li> <li><code>cnn_losses.py</code>: 0.5 days</li> <li><code>cnn_schedulers.py</code>: 0.5 days</li> <li><code>cnn_callbacks.py</code>: 0.5 days</li> <li> <p><code>cnn_optimizer.py</code>: 0.5 days</p> </li> <li> <p>Evaluation (4 files): 3 days</p> </li> <li><code>cnn_evaluator.py</code>: 1 day</li> <li><code>cnn_interpretability.py</code>: 1 day (Grad-CAM, Integrated Gradients)</li> <li><code>cnn_robustness.py</code>: 0.5 days</li> <li> <p><code>cnn_visualization.py</code>: 0.5 days</p> </li> <li> <p>Experiment management (3 files): 2 days</p> </li> <li><code>cnn_experiment.py</code>: 1 day</li> <li><code>cnn_hparam_search.py</code>: 0.5 days</li> <li> <p><code>cnn_ablation_study.py</code>: 0.5 days</p> </li> <li> <p>Utilities (3 files): 1 day</p> </li> <li>Testing (unit, integration, convergence): 4 days</li> <li>Hyperparameter tuning (find best config): 3 days</li> <li>Documentation: 2 days</li> <li>Buffer for debugging: 3 days</li> </ul> <p><strong>Total: ~27 days (1.3 months) for Phase 2</strong></p> <p><strong>Complexity</strong>: ⭐⭐⭐⭐☆ (High) - Deep learning requires GPU setup, debugging - Hyperparameter tuning is time-consuming - Interpretability methods (Grad-CAM) need careful implementation</p> <p><strong>Dependencies</strong>: Phase 0 (data), Phase 1 (baseline comparison)</p> <p><strong>Risk</strong>: Medium-High - May not match classical ML accuracy on first attempt (need tuning) - GPU availability/configuration issues - Mixed precision training may have numerical instabilities</p> <hr> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024-2026 Syed Abbas Ahmad </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/abbas-ahmad-cowlar/LSTM_PFD target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"annotate": null, "base": "../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.path", "navigation.top", "navigation.footer", "search.suggest", "search.highlight", "content.tabs.link", "content.code.copy", "content.code.annotate"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script> <script src=../../../assets/javascripts/bundle.79ae519e.min.js></script> <script src=../../../javascripts/mathjax.js></script> <script src=https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>